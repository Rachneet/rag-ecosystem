{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d5b5a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36f49d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from token import OP\n",
    "from langchain_huggingface import (\n",
    "    HuggingFaceEndpointEmbeddings,\n",
    "    HuggingFaceEndpoint,\n",
    "    ChatHuggingFace\n",
    ")\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def get_hf_llm(model_name: str, model_kwargs: Optional[dict]) -> ChatHuggingFace:\n",
    "\n",
    "    if not model_kwargs:\n",
    "        model_kwargs = {\n",
    "            \"max_new_tokens\": 1024,\n",
    "        }\n",
    "    model = HuggingFaceEndpoint(\n",
    "        model=model_name,\n",
    "        **model_kwargs\n",
    "    )\n",
    "    return ChatHuggingFace(llm=model)\n",
    "\n",
    "# test \n",
    "llm = get_hf_llm(\"meta-llama/Llama-3.1-8B-Instruct\", model_kwargs={})\n",
    "llm.invoke(\"Hi\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d8ea84",
   "metadata": {},
   "source": [
    "### Initialize the models to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550d5584",
   "metadata": {},
   "source": [
    "**We need to define a configuration dictionary to hold the clients for each of our chosen models. This way we can easily swap models and centralizes our model management.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c354f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary will act as our central registry, or \"foundry,\" for all LLM and embedding model clients.\n",
    "llm_config = {\n",
    "    # # For the 'planner', we use Llama 3.1 8B. It's a modern, \n",
    "    # highly capable model that excels at instruction-following.\n",
    "    \"planner\": get_hf_llm(\n",
    "        model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        model_kwargs={\"temperature\": 0.0}\n",
    "    ),\n",
    "    # For the 'drafter' and 'sql_coder', we use Qwen2 7B. It's a nimble and fast model, perfect for\n",
    "    # tasks like text generation and code completion where speed is valuable.\n",
    "    \"drafter\": get_hf_llm(\n",
    "        model_name=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "        model_kwargs={\"temperature\": 0.2}\n",
    "    ),\n",
    "    \"sql_coder\": get_hf_llm(\n",
    "        model_name=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "        model_kwargs={\"temperature\": 0.0}\n",
    "    ),\n",
    "    # For the 'director', the highest-level strategic agent, we use the powerful Llama 3 70B model.\n",
    "    # This high-stakes task of diagnosing performance and evolving the system's own procedures\n",
    "    # justifies the use of a larger, more powerful model.\n",
    "    \"director\": get_hf_llm(\n",
    "        model_name=\"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "        model_kwargs={\"temperature\": 0.0}\n",
    "    ),\n",
    "    # For embeddings, we use 'Qwen/Qwen3-Embedding-8B\",', a top-tier, efficient open-source model.\n",
    "    \"embedding_model\": HuggingFaceEndpointEmbeddings(\n",
    "        model=\"Qwen/Qwen3-Embedding-8B\",\n",
    "        task=\"feature-extraction\",\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f93634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test embedding model\n",
    "query = \"Hey that's a great tutorial.\"\n",
    "llm_config[\"embedding_model\"].embed_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa51219",
   "metadata": {},
   "source": [
    "So we have just created our llm_config dictionary, which serves as a centralized hub for all our model initializations. By assigning different models to different roles, we are creating a cost-performance optimized hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2643a",
   "metadata": {},
   "source": [
    "- **Fast & Nimble (7B-8B models)**: The planner, drafter, and sql_coder roles handle frequent, well-defined tasks. Using smaller models like Qwen2.5 7B and Llama 3.1 8B for these roles ensures low latency and efficient resource usage. They are perfectly capable of following instructions to generate plans, draft text, or write SQL.\n",
    "\n",
    "- **Deep & Strategic (70B model)**: The director agent has the most complex job, it must analyze multi-dimensional performance data and rewrite the entire system operating procedure. This requires deep reasoning and a understanding of cause and effect. For this high-stakes, low-frequency task, we allocate our most powerful resource, the Llama 3 70B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "754a8224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM clients configured:\n",
      "Planner (meta-llama/Llama-3.1-8B-Instruct): llm=HuggingFaceEndpoint(temperature=0.0, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='meta-llama/Llama-3.1-8B-Instruct', client=<InferenceClient(model='meta-llama/Llama-3.1-8B-Instruct', timeout=120)>, async_client=<InferenceClient(model='meta-llama/Llama-3.1-8B-Instruct', timeout=120)>) model_id='meta-llama/Llama-3.1-8B-Instruct' top_p=0.95 max_tokens=512 model_kwargs={}\n",
      "Drafter (Qwen/Qwen2.5-7B-Instruct): llm=HuggingFaceEndpoint(temperature=0.2, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='Qwen/Qwen2.5-7B-Instruct', client=<InferenceClient(model='Qwen/Qwen2.5-7B-Instruct', timeout=120)>, async_client=<InferenceClient(model='Qwen/Qwen2.5-7B-Instruct', timeout=120)>) model_id='Qwen/Qwen2.5-7B-Instruct' temperature=0.2 top_p=0.95 max_tokens=512 model_kwargs={}\n",
      "SQL Coder (Qwen/Qwen2.5-7B-Instruct): llm=HuggingFaceEndpoint(temperature=0.0, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='Qwen/Qwen2.5-7B-Instruct', client=<InferenceClient(model='Qwen/Qwen2.5-7B-Instruct', timeout=120)>, async_client=<InferenceClient(model='Qwen/Qwen2.5-7B-Instruct', timeout=120)>) model_id='Qwen/Qwen2.5-7B-Instruct' top_p=0.95 max_tokens=512 model_kwargs={}\n",
      "Director (meta-llama/Meta-Llama-3-70B-Instruct): llm=HuggingFaceEndpoint(temperature=0.0, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='meta-llama/Meta-Llama-3-70B-Instruct', client=<InferenceClient(model='meta-llama/Meta-Llama-3-70B-Instruct', timeout=120)>, async_client=<InferenceClient(model='meta-llama/Meta-Llama-3-70B-Instruct', timeout=120)>) model_id='meta-llama/Meta-Llama-3-70B-Instruct' top_p=0.95 max_tokens=512 model_kwargs={}\n",
      "Embedding Model (Qwen/Qwen3-Embedding-8B): client=<InferenceClient(model='Qwen/Qwen3-Embedding-8B', timeout=None)> async_client=<InferenceClient(model='Qwen/Qwen3-Embedding-8B', timeout=None)> model='Qwen/Qwen3-Embedding-8B' provider=None repo_id='Qwen/Qwen3-Embedding-8B' task='feature-extraction' model_kwargs=None huggingfacehub_api_token=None\n"
     ]
    }
   ],
   "source": [
    "# Print the configuration to confirm the clients are initialized and their parameters are set correctly.\n",
    "print(\"LLM clients configured:\")\n",
    "print(f\"Planner ({llm_config['planner'].model_id}): {llm_config['planner']}\")\n",
    "print(f\"Drafter ({llm_config['drafter'].model_id}): {llm_config['drafter']}\")\n",
    "print(f\"SQL Coder ({llm_config['sql_coder'].model_id}): {llm_config['sql_coder']}\")\n",
    "print(f\"Director ({llm_config['director'].model_id}): {llm_config['director']}\")\n",
    "print(f\"Embedding Model ({llm_config['embedding_model'].model}): {llm_config['embedding_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f1718",
   "metadata": {},
   "source": [
    "### Preparing the Knowledge Stores\n",
    "\n",
    "The most important part for a RAG pipeline is a rich multi-modal knowledge base to draw upon. A generic, web-based search is not enough for a specialized task like clinical trial design. We need to ground our agents in authoritative, domain-specific information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0bf3b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: ./data\n",
      "Created directory: ./data/pubmed_articles\n",
      "Created directory: ./data/fda_guidelines\n",
      "Created directory: ./data/ethical_guidelines\n",
      "Created directory: ./data/mimic_db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# A dictionary to hold the paths for our different data types. This keeps our file management clean and centralized.\n",
    "data_paths = {\n",
    "    \"base\": \"./data\",\n",
    "    \"pubmed\": \"./data/pubmed_articles\",\n",
    "    \"fda\": \"./data/fda_guidelines\",\n",
    "    \"ethics\": \"./data/ethical_guidelines\",\n",
    "    \"mimic\": \"./data/mimic_db\"\n",
    "}\n",
    "# This loop iterates through our defined paths and uses os.makedirs() to create any directories that don't already exist.\n",
    "# This prevents errors in later steps when we try to save files to these locations.\n",
    "for path in data_paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Created directory: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf399f0c",
   "metadata": {},
   "source": [
    "Download Pubmed articles for our medical researcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a703212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "\n",
    "def download_pubmed_articles(query, max_articles=20):\n",
    "    \"\"\"Fetches abstracts from PubMed for a given query and saves them as text files.\"\"\"\n",
    "    # The NCBI API requires an email address for identification. We fetch it from our environment variables.\n",
    "    Entrez.email = os.environ.get(\"ENTREZ_EMAIL\")\n",
    "    print(f\"Fetching PubMed articles for query: {query}\")\n",
    "    \n",
    "    # Step 1: Use Entrez.esearch to find the PubMed IDs (PMIDs) for articles matching our query.\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_articles, sort=\"relevance\")\n",
    "    record = Entrez.read(handle)\n",
    "    id_list = record[\"IdList\"]\n",
    "    print(f\"Found {len(id_list)} article IDs.\")\n",
    "    \n",
    "    print(\"Downloading articles...\")\n",
    "    # Step 2: Use Entrez.efetch to retrieve the full records (in MEDLINE format) for the list of PMIDs.\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=id_list, rettype=\"medline\", retmode=\"text\")\n",
    "    records = Medline.parse(handle)\n",
    "    \n",
    "    count = 0\n",
    "    # Step 3: Iterate through the retrieved records, parse them, and save each abstract to a file.\n",
    "    for i, record in enumerate(records):\n",
    "        pmid = record.get(\"PMID\", \"\")\n",
    "        title = record.get(\"TI\", \"No Title\")\n",
    "        abstract = record.get(\"AB\", \"No Abstract\")\n",
    "        if pmid:\n",
    "            # We name the file after the PMID for easy reference and to avoid duplicates.\n",
    "            filepath = os.path.join(data_paths[\"pubmed\"], f\"{pmid}.txt\")\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(f\"Title: {title}\\n\\nAbstract: {abstract}\")\n",
    "            print(f\"[{i+1}/{len(id_list)}] Fetching PMID: {pmid}... Saved to {filepath}\")\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ed7902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching PubMed articles for query: (SGLT2 inhibitor) AND (type 2 diabetes) AND (renal impairment)\n",
      "Found 20 article IDs.\n",
      "Downloading articles...\n",
      "[1/20] Fetching PMID: 36945734... Saved to ./data/pubmed_articles/36945734.txt\n",
      "[2/20] Fetching PMID: 40470996... Saved to ./data/pubmed_articles/40470996.txt\n",
      "[3/20] Fetching PMID: 38914124... Saved to ./data/pubmed_articles/38914124.txt\n",
      "[4/20] Fetching PMID: 30697905... Saved to ./data/pubmed_articles/30697905.txt\n",
      "[5/20] Fetching PMID: 36335326... Saved to ./data/pubmed_articles/36335326.txt\n",
      "[6/20] Fetching PMID: 36351458... Saved to ./data/pubmed_articles/36351458.txt\n",
      "[7/20] Fetching PMID: 40327845... Saved to ./data/pubmed_articles/40327845.txt\n",
      "[8/20] Fetching PMID: 35113333... Saved to ./data/pubmed_articles/35113333.txt\n",
      "[9/20] Fetching PMID: 34619106... Saved to ./data/pubmed_articles/34619106.txt\n",
      "[10/20] Fetching PMID: 33413348... Saved to ./data/pubmed_articles/33413348.txt\n",
      "[11/20] Fetching PMID: 34272327... Saved to ./data/pubmed_articles/34272327.txt\n",
      "[12/20] Fetching PMID: 34817311... Saved to ./data/pubmed_articles/34817311.txt\n",
      "[13/20] Fetching PMID: 35145275... Saved to ./data/pubmed_articles/35145275.txt\n",
      "[14/20] Fetching PMID: 33878338... Saved to ./data/pubmed_articles/33878338.txt\n",
      "[15/20] Fetching PMID: 38052474... Saved to ./data/pubmed_articles/38052474.txt\n",
      "[16/20] Fetching PMID: 28432726... Saved to ./data/pubmed_articles/28432726.txt\n",
      "[17/20] Fetching PMID: 38913113... Saved to ./data/pubmed_articles/38913113.txt\n",
      "[18/20] Fetching PMID: 31101403... Saved to ./data/pubmed_articles/31101403.txt\n",
      "[19/20] Fetching PMID: 28904068... Saved to ./data/pubmed_articles/28904068.txt\n",
      "[20/20] Fetching PMID: 38684099... Saved to ./data/pubmed_articles/38684099.txt\n",
      "PubMed download complete. 20 articles saved.\n"
     ]
    }
   ],
   "source": [
    "# We define a specific, boolean query to find articles highly relevant to our trial concept.\n",
    "pubmed_query = \"(SGLT2 inhibitor) AND (type 2 diabetes) AND (renal impairment)\"\n",
    "num_downloaded = download_pubmed_articles(pubmed_query)\n",
    "print(f\"PubMed download complete. {num_downloaded} articles saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22bdfe2",
   "metadata": {},
   "source": [
    "Now, let’s get the regulatory documents that our Regulatory Specialist agent will need. A key part of trial design is ensuring compliance with government guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6106288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import read\n",
    "import requests\n",
    "from pypdf import PdfReader\n",
    "import io\n",
    "\n",
    "def download_and_extract_text_from_pdf(url, output_path, download=False):\n",
    "    \"\"\"Downloads a PDF from a URL, saves it, and also extracts its text content to a separate .txt file.\"\"\"\n",
    "    print(f\"Downloading FDA Guideline: {url}\")\n",
    "    try:\n",
    "        # We use the 'requests' library to perform the HTTP GET request to download the file.\n",
    "        if download:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status() # This is a good practice that will raise an error if the download fails (e.g., a 404 error).\n",
    "        \n",
    "            # We save the raw PDF file, which is useful for archival purposes.\n",
    "            with open(output_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Successfully downloaded and saved to {output_path}\")\n",
    "        \n",
    "            # We then use pypdf to read the PDF content directly from the in-memory response.\n",
    "            reader = PdfReader(io.BytesIO(response.content))\n",
    "        else:\n",
    "            reader = PdfReader(output_path)\n",
    "        text = \"\"\n",
    "        # We loop through each page of the PDF and append its extracted text.\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\\n\"\n",
    "        \n",
    "        # Finally, we save the clean, extracted text to a .txt file. This is the file our RAG system will actually use.\n",
    "        txt_output_path = os.path.splitext(output_path)[0] + '.txt'\n",
    "        with open(txt_output_path, 'w') as f:\n",
    "            f.write(text)\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b48c8",
   "metadata": {},
   "source": [
    "This function, download_and_extract_text_from_pdf, is our tool for handling PDF documents. It's a two-stage process.\n",
    "\n",
    "- First, it downloads and saves the original PDF from the FDA website. Second, and more importantly, it immediately processes that PDF using pypdf to extract all the text content.\n",
    "\n",
    "- It then saves this raw text to a .txt file. This pre-processing step is crucial because it converts the complex PDF format into simple text that our document loaders can easily ingest when we build our vector stores later on.\n",
    "\n",
    "Let’s run the function to download our FDA guidance document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88d428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading FDA Guideline: https://www.fda.gov/media/71185/download\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This URL points to a real FDA guidance document for developing drugs for diabetes.\n",
    "fda_url = \"https://www.fda.gov/media/71185/download\"\n",
    "fda_pdf_path = os.path.join(data_paths[\"fda\"], \"fda_diabetes_guidance_ocr.pdf\")\n",
    "download_and_extract_text_from_pdf(fda_url, fda_pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec8a78",
   "metadata": {},
   "source": [
    "Instructions for ethics specialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee43ac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ethics guideline file: ./data/ethical_guidelines/belmont_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# This multi-line string contains a curated summary of the three core principles of the Belmont Report,\n",
    "# which is the foundational document for ethics in human subject research in the United States.\n",
    "ethics_content = \"\"\"\n",
    "Title: Summary of the Belmont Report Principles for Clinical Research\n",
    "1. Respect for Persons: This principle requires that individuals be treated as autonomous agents and that persons with diminished autonomy are entitled to protection. This translates to robust informed consent processes. Inclusion/exclusion criteria must not unduly target or coerce vulnerable populations, such as economically disadvantaged individuals, prisoners, or those with severe cognitive impairments, unless the research is directly intended to benefit that population.\n",
    "2. Beneficence: This principle involves two complementary rules: (1) do not harm and (2) maximize possible benefits and minimize possible harms. The criteria must be designed to select a population that is most likely to benefit and least likely to be harmed by the intervention. The risks to subjects must be reasonable in relation to anticipated benefits.\n",
    "3. Justice: This principle concerns the fairness of distribution of the burdens and benefits of research. The selection of research subjects must be equitable. Criteria should not be designed to exclude certain groups without a sound scientific or safety-related justification. For example, excluding participants based on race, gender, or socioeconomic status is unjust unless there is a clear rationale related to the drug's mechanism or risk profile.\n",
    "\"\"\"\n",
    "\n",
    "# We define the path where our ethics document will be saved.\n",
    "ethics_path = os.path.join(data_paths[\"ethics\"], \"belmont_summary.txt\")\n",
    "\n",
    "# We open the file in write mode and save the content.\n",
    "with open(ethics_path, \"w\") as f:\n",
    "    f.write(ethics_content)\n",
    "print(f\"Created ethics guideline file: {ethics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43936258",
   "metadata": {},
   "source": [
    "Now for our most complex data source: the structured clinical data from MIMIC-III. This will provide the real-world population data our Patient Cohort Analyst needs to assess recruitment feasibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "13bdd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def load_real_mimic_data():\n",
    "    \"\"\"Loads real MIMIC-III CSVs into a persistent DuckDB database file, processing the massive LABEVENTS table efficiently.\"\"\"\n",
    "    print(\"Attempting to load real MIMIC-III data from local CSVs...\")\n",
    "    db_path = os.path.join(data_paths[\"mimic\"], \"mimic3_real.db\")\n",
    "    csv_dir = os.path.join(data_paths[\"mimic\"], \"mimiciii_csvs\")\n",
    "    \n",
    "    # Define the paths to the required compressed CSV files.\n",
    "    required_files = {\n",
    "        \"patients\": os.path.join(csv_dir, \"PATIENTS.csv\"),\n",
    "        \"diagnoses\": os.path.join(csv_dir, \"DIAGNOSES_ICD.csv\"),\n",
    "        \"labevents\": os.path.join(csv_dir, \"LABEVENTS.csv\"),\n",
    "    }\n",
    "    \n",
    "    # Before starting, we check if all the necessary source files are present.\n",
    "    missing_files = [path for path in required_files.values() if not os.path.exists(path)]\n",
    "    if missing_files:\n",
    "        print(\"ERROR: The following MIMIC-III files were not found:\")\n",
    "        for f in missing_files: print(f\"- {f}\")\n",
    "        print(\"\\nPlease download them as instructed and place them in the correct directory.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Required files found. Proceeding with database creation.\")\n",
    "    # Remove any old database file to ensure we are building from scratch.\n",
    "    if os.path.exists(db_path):\n",
    "        os.remove(db_path)\n",
    "    # Connect to DuckDB. If the database file doesn't exist, it will be created.\n",
    "    con = duckdb.connect(db_path)\n",
    "    \n",
    "    # Use DuckDB's powerful `read_csv_auto` to directly load data from the gzipped CSVs into SQL tables.\n",
    "    print(f\"Loading {required_files['patients']} into DuckDB...\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS patients\")\n",
    "    con.execute(f\"CREATE TABLE patients AS SELECT SUBJECT_ID, GENDER, DOB, DOD FROM read_csv_auto('{required_files['patients']}')\")\n",
    "    \n",
    "    print(f\"Loading {required_files['diagnoses']} into DuckDB...\")\n",
    "    con.execute(f\"CREATE TABLE diagnoses_icd AS SELECT SUBJECT_ID, ICD9_CODE FROM read_csv_auto('{required_files['diagnoses']}')\")\n",
    "    \n",
    "    # The LABEVENTS table is enormous. To handle it robustly, we use a two-stage process.\n",
    "    print(f\"Loading and processing {required_files['labevents']} (this may take several minutes)...\")\n",
    "    # 1. Load the data into a temporary 'staging' table, treating all columns as text (`all_varchar=True`).\n",
    "    #    This prevents parsing errors with mixed data types. We also filter for only the lab item IDs we\n",
    "    #    care about (50912 for Creatinine, 50852 for HbA1c) and use a regex to ensure VALUENUM is numeric.\n",
    "    con.execute(f\"\"\"CREATE TABLE labevents_staging AS \n",
    "                   SELECT SUBJECT_ID, ITEMID, VALUENUM \n",
    "                   FROM read_csv_auto('{required_files['labevents']}', all_varchar=True) \n",
    "                   WHERE ITEMID IN ('50912', '50852') AND VALUENUM IS NOT NULL AND VALUENUM ~ '^[0-9]+(\\\\.[0-9]+)?$'\n",
    "                \"\"\")\n",
    "    # 2. Create the final, clean table by selecting from the staging table and casting the columns to their correct numeric types.\n",
    "    con.execute(\"CREATE TABLE labevents AS SELECT SUBJECT_ID, CAST(ITEMID AS INTEGER) AS ITEMID, CAST(VALUENUM AS DOUBLE) AS VALUENUM FROM labevents_staging\")\n",
    "    # 3. Drop the temporary staging table to save space.\n",
    "    con.execute(\"DROP TABLE labevents_staging\")\n",
    "    con.close()\n",
    "    return db_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7789c14f",
   "metadata": {},
   "source": [
    "Instead of trying to load the massive MIMIC-III CSV files into memory with pandas (which would likely crash), we are usingDuckDB ability to process data directly from disk. The two-stage processing of theLABEVENTS table is a critical technique. By first loading the data as text and filtering it before casting to numeric types, before this we handle data quality issues and create a final table that is smaller, cleaner, and much faster to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "720ac595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load real MIMIC-III data from local CSVs...\n",
      "Required files found. Proceeding with database creation.\n",
      "Loading ./data/mimic_db/mimiciii_csvs/PATIENTS.csv into DuckDB...\n",
      "Loading ./data/mimic_db/mimiciii_csvs/DIAGNOSES_ICD.csv into DuckDB...\n",
      "Loading and processing ./data/mimic_db/mimiciii_csvs/LABEVENTS.csv (this may take several minutes)...\n",
      "\n",
      "Real MIMIC-III database created at: ./data/mimic_db/mimic3_real.db\n",
      "\n",
      "Testing database connection and schema...\n",
      "Tables in DB: ['diagnoses_icd', 'labevents', 'patients']\n",
      "\n",
      "Sample of 'patients' table:\n",
      "   subject_id gender        dob        dod\n",
      "0       10006      F 2094-03-05 2165-08-12\n",
      "1       10011      F 2090-06-05 2126-08-28\n",
      "2       10013      F 2038-09-03 2125-10-07\n",
      "3       10017      F 2075-09-21 2152-09-12\n",
      "4       10019      M 2114-06-20 2163-05-15\n",
      "\n",
      "Sample of 'diagnoses_icd' table:\n",
      "   subject_id icd9_code\n",
      "0       10006     99591\n",
      "1       10006     99662\n",
      "2       10006      5672\n",
      "3       10006     40391\n",
      "4       10006     42731\n"
     ]
    }
   ],
   "source": [
    "# Execute the function to build the database.\n",
    "db_path = load_real_mimic_data()\n",
    "\n",
    "# If the database was created successfully, connect to it and inspect the schema and some sample data.\n",
    "if db_path:\n",
    "    print(f\"\\nReal MIMIC-III database created at: {db_path}\")\n",
    "    print(\"\\nTesting database connection and schema...\")\n",
    "    con = duckdb.connect(db_path)\n",
    "    print(f\"Tables in DB: {con.execute('SHOW TABLES').df()['name'].tolist()}\")\n",
    "    print(\"\\nSample of 'patients' table:\")\n",
    "    print(con.execute(\"SELECT * FROM patients LIMIT 5\").df())\n",
    "    print(\"\\nSample of 'diagnoses_icd' table:\")\n",
    "    print(con.execute(\"SELECT * FROM diagnoses_icd LIMIT 5\").df())\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f83b619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id gender        dob        dod\n",
      "0       10006      F 2094-03-05 2165-08-12\n",
      "1       10011      F 2090-06-05 2126-08-28\n",
      "2       10013      F 2038-09-03 2125-10-07\n",
      "3       10017      F 2075-09-21 2152-09-12\n",
      "4       10019      M 2114-06-20 2163-05-15\n"
     ]
    }
   ],
   "source": [
    "con = duckdb.connect(db_path)\n",
    "print(con.execute(\"SELECT * FROM patients LIMIT 5\").df())\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe0a3b3",
   "metadata": {},
   "source": [
    "Our Patient Cohort Analyst agent now has access to a high-performance, real-world clinical database containing millions of records, enabling it to provide truly data-grounded feasibility estimates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb7205",
   "metadata": {},
   "source": [
    "Finally, let’s index all our unstructured text data into searchable vector stores. This will make the PubMed, FDA, and ethics documents accessible to our RAG agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6b851e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from torch import chunk\n",
    "\n",
    "def create_vector_store(folder_path: str, embedding_model: HuggingFaceEndpointEmbeddings, store_name: str):\n",
    "    \"\"\"Loads all .txt files from a folder, splits them into chunks, and creates an in-memory FAISS vector store.\"\"\"\n",
    "    loader = DirectoryLoader(\n",
    "        path=folder_path,\n",
    "        glob=\"**/*.txt\",\n",
    "        show_progress=True,\n",
    "        loader_cls=TextLoader,\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    texts = text_splitter.split_documents(documents=documents)\n",
    "    db = FAISS.from_documents(texts, embedding=embedding_model)\n",
    "    print(f\"{store_name} Vector Store created successfully.\")\n",
    "    return db\n",
    "\n",
    "\n",
    "def create_retrievers(embedding_model: HuggingFaceEndpointEmbeddings):\n",
    "    \"\"\"Creates vector store retrievers for all unstructured data sources and consolidates all knowledge stores.\"\"\"\n",
    "    # Create a separate, specialized vector store for each type of document.\n",
    "    pubmed_db = create_vector_store(data_paths[\"pubmed\"], embedding_model, \"PubMed\")\n",
    "    fda_db = create_vector_store(data_paths[\"fda\"], embedding_model, \"FDA\")\n",
    "    ethics_db = create_vector_store(data_paths[\"ethics\"], embedding_model, \"Ethics\")\n",
    "    \n",
    "    # Return a single dictionary containing all configured data access tools.\n",
    "    # The 'as_retriever' method converts the vector store into a standard LangChain Retriever object.\n",
    "    # The 'k' parameter in 'search_kwargs' controls how many top documents are returned by a search.\n",
    "    return {\n",
    "        \"pubmed_retriever\": pubmed_db.as_retriever(search_kwargs={\"k\": 3}) if pubmed_db else None,\n",
    "        \"fda_retriever\": fda_db.as_retriever(search_kwargs={\"k\": 3}) if fda_db else None,\n",
    "        \"ethics_retriever\": ethics_db.as_retriever(search_kwargs={\"k\": 2}) if ethics_db else None,\n",
    "        \"mimic_db_path\": db_path # We also include the file path to our structured DuckDB database.\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "199388e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 2676.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PubMed Vector Store created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1748.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDA Vector Store created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 842.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethics Vector Store created successfully.\n",
      "\n",
      "Knowledge stores and retrievers created successfully.\n",
      "pubmed_retriever: tags=['FAISS', 'HuggingFaceEndpointEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1486f97f0> search_kwargs={'k': 3}\n",
      "fda_retriever: tags=['FAISS', 'HuggingFaceEndpointEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12c7ea0c0> search_kwargs={'k': 3}\n",
      "ethics_retriever: tags=['FAISS', 'HuggingFaceEndpointEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1486f9850> search_kwargs={'k': 2}\n",
      "mimic_db_path: ./data/mimic_db/mimic3_real.db\n"
     ]
    }
   ],
   "source": [
    "# Execute the function to create all our retrievers.\n",
    "knowledge_stores = create_retrievers(llm_config[\"embedding_model\"])\n",
    "\n",
    "print(\"\\nKnowledge stores and retrievers created successfully.\")\n",
    "\n",
    "# Print the final dictionary to confirm all components are present.\n",
    "for name, store in knowledge_stores.items():\n",
    "    print(f\"{name}: {store}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220738f3",
   "metadata": {},
   "source": [
    "### Building The Inner Trial Design Network\n",
    "\n",
    "With our knowledge base is now ready, we can now construct the core of our system. This is not going to be a simple, linear RAG chain. It is a collaborative, multi-agent workflow built with LangGraph, where a team of AI specialists works together to transform a high-level trial concept into a detailed, data-grounded criteria document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "88bcf0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class GuildSOP(BaseModel):\n",
    "    \"\"\"Standard Operating Procedures for the Trial Design Guild. This object acts as the dynamic configuration for the entire RAG workflow.\"\"\"\n",
    "    \n",
    "    # This field holds the system prompt for the Planner Agent, dictating its strategy.\n",
    "    planner_prompt: str = Field(description=\"The system prompt for the Planner Agent.\")\n",
    "    \n",
    "    # This parameter controls how many documents the Medical Researcher retrieves, allowing us to tune the breadth of its search.\n",
    "    researcher_retriever_k: int = Field(description=\"Number of documents for the Medical Researcher to retrieve.\", default=3)\n",
    "    \n",
    "    # This is the system prompt for the final writer, the Synthesizer Agent.\n",
    "    synthesizer_prompt: str = Field(description=\"The system prompt for the Criteria Synthesizer Agent.\")\n",
    "    \n",
    "    # This allows us to dynamically change the model used for the final drafting stage, trading off speed vs. quality.\n",
    "    synthesizer_model: Literal[\"Qwen/Qwen2.5-7B-Instruct\", \"meta-llama/Llama-3.1-8B-Instruct\"] = Field(\n",
    "        description=\"The LLM to use for the Synthesizer.\", \n",
    "        default=\"Qwen/Qwen2.5-7B-Instruct\"\n",
    "    )\n",
    "    \n",
    "    # These booleans act as \"feature flags,\" allowing the Director to turn entire agent capabilities on or off.\n",
    "    use_sql_analyst: bool = Field(description=\"Whether to use the Patient Cohort Analyst agent.\", default=True)\n",
    "    use_ethics_specialist: bool = Field(description=\"Whether to use the Ethics Specialist agent.\", default=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed785c",
   "metadata": {},
   "source": [
    "Now that we have the blueprint for our SOP, let’s create a concrete, version 1.0 instance. This baseline_sop will be our starting point, the initial, hand-engineered strategy that we will task our AI Director with improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1195ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# We instantiate our GuildSOP class with a set of default, baseline values.\n",
    "baseline_sop = GuildSOP(\n",
    "    # The initial planner prompt is very detailed, instructing the agent on its role, the specialists available, and the required JSON output format.\n",
    "    planner_prompt=\"\"\"You are a master planner for clinical trial design. Your task is to receive a high-level trial concept and break it down into a structured plan with specific sub-tasks for a team of specialists: a Regulatory Specialist, a Medical Researcher, an Ethics Specialist, and a Patient Cohort Analyst. Output a JSON object with a single key 'plan' containing a list of tasks. Each task must have 'agent', 'task_description', and 'dependencies' keys.\"\"\",\n",
    "    \n",
    "    # The synthesizer prompt instructs the final writer on how to structure the output document.\n",
    "    synthesizer_prompt=\"\"\"You are an expert medical writer. Your task is to synthesize the structured findings from all specialist teams into a formal 'Inclusion and Exclusion Criteria' document. Be concise, precise, and adhere strictly to the information provided. Structure your output into two sections: 'Inclusion Criteria' and 'Exclusion Criteria'.\"\"\",\n",
    "    \n",
    "    # We'll start with a default retrieval of 3 documents for the researcher.\n",
    "    researcher_retriever_k=3,\n",
    "    \n",
    "    # We'll use the fast qwen2:7b model for the synthesizer initially.\n",
    "    synthesizer_model=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    \n",
    "    # By default, we'll use all our specialist agents.\n",
    "    use_sql_analyst=True,\n",
    "    use_ethics_specialist=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "924d6129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline GuildSOP (v1.0):\n",
      "{\n",
      "    \"planner_prompt\": \"You are a master planner for clinical trial design. Your task is to receive a high-level trial concept and break it down into a structured plan with specific sub-tasks for a team of specialists: a Regulatory Specialist, a Medical Researcher, an Ethics Specialist, and a Patient Cohort Analyst. Output a JSON object with a single key 'plan' containing a list of tasks. Each task must have 'agent', 'task_description', and 'dependencies' keys.\",\n",
      "    \"researcher_retriever_k\": 3,\n",
      "    \"synthesizer_prompt\": \"You are an expert medical writer. Your task is to synthesize the structured findings from all specialist teams into a formal 'Inclusion and Exclusion Criteria' document. Be concise, precise, and adhere strictly to the information provided. Structure your output into two sections: 'Inclusion Criteria' and 'Exclusion Criteria'.\",\n",
      "    \"synthesizer_model\": \"Qwen/Qwen2.5-7B-Instruct\",\n",
      "    \"use_sql_analyst\": true,\n",
      "    \"use_ethics_specialist\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline GuildSOP (v1.0):\")\n",
    "# We use .dict() to convert the Pydantic model to a dictionary and json.dumps for clean printing.\n",
    "print(json.dumps(baseline_sop.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a99d9b",
   "metadata": {},
   "source": [
    "### Defining the Specialist Agents\n",
    "\n",
    "Now that we have the rulebook (the SOP), we need to define the agents themselves. In LangGraph, agents are represented as nodes, which are simply Python functions that take the current graph state as input and return an update to that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "840bee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# We first define a structure for a single agent's output.\n",
    "# This ensures every agent's findings are packaged consistently with clear attribution.\n",
    "class AgentOutput(BaseModel):\n",
    "    \"\"\"A structured output for each agent's findings.\"\"\"\n",
    "    agent_name: str\n",
    "    findings: Any\n",
    "\n",
    "# Now we define the main state for the entire Guild workflow.\n",
    "class GuildState(TypedDict):\n",
    "    \"\"\"The state of the Trial Design Guild's workflow, passed between all nodes.\"\"\"\n",
    "    initial_request: str                   # The user's initial high-level trial concept.\n",
    "    plan: Optional[Dict[str, Any]]         # The structured plan generated by the Planner.\n",
    "    agent_outputs: List[AgentOutput]       # An accumulating list of findings from each specialist.\n",
    "    final_criteria: Optional[str]          # The final, synthesized document.\n",
    "    sop: GuildSOP                          # The dynamic SOP for this specific run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4012240",
   "metadata": {},
   "source": [
    "### Multi-agent framework\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../figures/medical_agent_arch.webp\" width=\"1200\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790621a",
   "metadata": {},
   "source": [
    "### Planner agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1b692e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "class PlannerOutput(BaseModel):\n",
    "    plan: List = Field(..., description=\"The plan to follow.\")\n",
    "\n",
    "\n",
    "def planner_agent(state: GuildState) -> GuildState:\n",
    "    \"\"\"Receives the initial request and creates a structured plan for the specialist agents.\"\"\"\n",
    "    print(\"--- EXECUTING PLANNER AGENT ---\")\n",
    "\n",
    "    # Retrieve the current SOP from the state. This allows its behavior to be dynamic.\n",
    "    sop = state['sop']\n",
    "\n",
    "    # Configure the 'planner' LLM to expect a JSON output that matches the schema {'plan': []}.\n",
    "    planner_llm = llm_config['planner']  # with_structured_output(schema={\"plan\": []})\n",
    "\n",
    "    output_parser = JsonOutputParser(\n",
    "        name=\"research_parser\",\n",
    "        pydantic_object=PlannerOutput\n",
    "    )\n",
    "    \n",
    "    # Construct the full prompt by combining the generic prompt from the SOP with the specific trial concept for this run.\n",
    "    template = \"\"\"{planner_prompt}\\n\\nTrial Concept: '{initial_request}'\\n\\n{format_instructions}\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        template=template,\n",
    "        partial_variables={\"format_instructions\":output_parser.get_format_instructions()}\n",
    "    )\n",
    "    print(f\"Planner Prompt:\\n{prompt}\")\n",
    "\n",
    "    research_chain = prompt | planner_llm | output_parser\n",
    "    \n",
    "    # # Invoke the LLM to generate the plan.\n",
    "    response = research_chain.invoke({\n",
    "        \"planner_prompt\": sop[\"planner_prompt\"] if isinstance(sop, dict) else sop.planner_prompt,\n",
    "        \"initial_request\": state[\"initial_request\"]\n",
    "    })\n",
    "    print(f\"Generated Plan:\\n{json.dumps(response, indent=2)}\")\n",
    "    \n",
    "    # Return an update to the state, adding the newly generated plan.\n",
    "    return {**state, \"plan\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "05b59562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the full Guild graph with baseline SOP v1.0...\n",
      "--- EXECUTING PLANNER AGENT ---\n",
      "Planner Prompt:\n",
      "input_variables=['initial_request', 'planner_prompt'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['initial_request', 'planner_prompt'], input_types={}, partial_variables={'format_instructions': 'STRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only — do not include any backticks or Markdown in your output):\\n```\\n{\"properties\": {\"plan\": {\"description\": \"The plan to follow.\", \"items\": {}, \"title\": \"Plan\", \"type\": \"array\"}}, \"required\": [\"plan\"]}\\n```'}, template=\"{planner_prompt}\\n\\nTrial Concept: '{initial_request}'\\n\\n{format_instructions}\"), additional_kwargs={})]\n",
      "Generated Plan:\n",
      "{\n",
      "  \"plan\": [\n",
      "    {\n",
      "      \"agent\": \"Regulatory Specialist\",\n",
      "      \"task_description\": \"Establish the regulatory pathway for Sotagliflozin in the treatment of uncontrolled Type 2 Diabetes and moderate CKD Stage 3\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Medical Researcher\",\n",
      "      \"task_description\": \"Draft the protocol for the Phase II trial, including objectives, population demographics, and inclusion/exclusion criteria\",\n",
      "      \"dependencies\": [\n",
      "        \"Regulatory Pathway Established\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Ethics Specialist\",\n",
      "      \"task_description\": \"Review and ensure compliance with relevant regulations and guidelines, including ICH-GCP and local regulations\",\n",
      "      \"dependencies\": [\n",
      "        \"Protocol Drafted\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Patient Cohort Analyst\",\n",
      "      \"task_description\": \"Identify and select a patient cohort for the trial, ensuring a representative sample of adults with uncontrolled Type 2 Diabetes and moderate CKD Stage 3\",\n",
      "      \"dependencies\": [\n",
      "        \"Inclusion/Exclusion Criteria Finalized\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Regulatory Specialist\",\n",
      "      \"task_description\": \"Obtain necessary regulatory approvals for the trial, including Institutional Review Board (IRB) and local regulatory agency approval\",\n",
      "      \"dependencies\": [\n",
      "        \"Ethics Review Completed\",\n",
      "        \"Patient Cohort Selected\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Medical Researcher\",\n",
      "      \"task_description\": \"Finalize the inclusion/exclusion criteria for the trial, incorporating feedback from the Ethics Specialist and Patient Cohort Analyst\",\n",
      "      \"dependencies\": [\n",
      "        \"Patient Cohort Selected\",\n",
      "        \"Regulatory Approvals Obtained\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'initial_request': \"Draft inclusion/exclusion criteria for a Phase II trial of 'Sotagliflozin', a novel SGLT2 inhibitor, for adults with uncontrolled Type 2 Diabetes (HbA1c > 8.0%) and moderate chronic kidney disease (CKD Stage 3).\",\n",
       " 'sop': GuildSOP(planner_prompt=\"You are a master planner for clinical trial design. Your task is to receive a high-level trial concept and break it down into a structured plan with specific sub-tasks for a team of specialists: a Regulatory Specialist, a Medical Researcher, an Ethics Specialist, and a Patient Cohort Analyst. Output a JSON object with a single key 'plan' containing a list of tasks. Each task must have 'agent', 'task_description', and 'dependencies' keys.\", researcher_retriever_k=3, synthesizer_prompt=\"You are an expert medical writer. Your task is to synthesize the structured findings from all specialist teams into a formal 'Inclusion and Exclusion Criteria' document. Be concise, precise, and adhere strictly to the information provided. Structure your output into two sections: 'Inclusion Criteria' and 'Exclusion Criteria'.\", synthesizer_model='Qwen/Qwen2.5-7B-Instruct', use_sql_analyst=True, use_ethics_specialist=True),\n",
       " 'plan': {'plan': [{'agent': 'Regulatory Specialist',\n",
       "    'task_description': 'Establish the regulatory pathway for Sotagliflozin in the treatment of uncontrolled Type 2 Diabetes and moderate CKD Stage 3',\n",
       "    'dependencies': []},\n",
       "   {'agent': 'Medical Researcher',\n",
       "    'task_description': 'Draft the protocol for the Phase II trial, including objectives, population demographics, and inclusion/exclusion criteria',\n",
       "    'dependencies': ['Regulatory Pathway Established']},\n",
       "   {'agent': 'Ethics Specialist',\n",
       "    'task_description': 'Review and ensure compliance with relevant regulations and guidelines, including ICH-GCP and local regulations',\n",
       "    'dependencies': ['Protocol Drafted']},\n",
       "   {'agent': 'Patient Cohort Analyst',\n",
       "    'task_description': 'Identify and select a patient cohort for the trial, ensuring a representative sample of adults with uncontrolled Type 2 Diabetes and moderate CKD Stage 3',\n",
       "    'dependencies': ['Inclusion/Exclusion Criteria Finalized']},\n",
       "   {'agent': 'Regulatory Specialist',\n",
       "    'task_description': 'Obtain necessary regulatory approvals for the trial, including Institutional Review Board (IRB) and local regulatory agency approval',\n",
       "    'dependencies': ['Ethics Review Completed', 'Patient Cohort Selected']},\n",
       "   {'agent': 'Medical Researcher',\n",
       "    'task_description': 'Finalize the inclusion/exclusion criteria for the trial, incorporating feedback from the Ethics Specialist and Patient Cohort Analyst',\n",
       "    'dependencies': ['Patient Cohort Selected',\n",
       "     'Regulatory Approvals Obtained']}]}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "# This is our high-level request, the initial spark for the entire workflow.\n",
    "test_request = \"Draft inclusion/exclusion criteria for a Phase II trial of 'Sotagliflozin', a novel SGLT2 inhibitor, for adults with uncontrolled Type 2 Diabetes (HbA1c > 8.0%) and moderate chronic kidney disease (CKD Stage 3).\"\n",
    "\n",
    "print(\"Running the full Guild graph with baseline SOP v1.0...\")\n",
    "# We prepare the initial state for the graph, providing the request and our baseline SOP.\n",
    "graph_input = {\n",
    "    \"initial_request\": test_request,\n",
    "    \"sop\": baseline_sop\n",
    "}\n",
    "\n",
    "planner_agent(graph_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac274f7e",
   "metadata": {},
   "source": [
    "We now need to build the specialist agents that will execute its plan. To avoid writing repetitive code, we’ll start by creating a generic, reusable function for all our RAG-based specialists (the Medical Researcher, Regulatory Specialist, and Ethics Specialist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ba0bf0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_agent(task_description: str, state: GuildState, retriever_name: str, agent_name: str) -> AgentOutput:\n",
    "    \"\"\"A generic agent function that performs retrieval from a specified vector store based on a task description.\"\"\"\n",
    "    print(f\"--- EXECUTING {agent_name.upper()} ---\")\n",
    "    print(f\"Task: {task_description}\")\n",
    "    \n",
    "    # Select the correct retriever from our global 'knowledge_stores' dictionary.\n",
    "    retriever = knowledge_stores[retriever_name]\n",
    "    \n",
    "    # This is a key dynamic feature: if the agent is the Medical Researcher,\n",
    "    # we override its 'k' value (number of documents to retrieve) with the value from the current SOP.\n",
    "    if agent_name == \"Medical Researcher\":\n",
    "        retriever.search_kwargs['k'] = state['sop'].researcher_retriever_k\n",
    "        print(f\"Using k={state['sop'].researcher_retriever_k} for retrieval.\")\n",
    "\n",
    "    # Invoke the retriever with the task description to find relevant documents.\n",
    "    retrieved_docs = retriever.invoke(task_description)\n",
    "    \n",
    "    # Format the findings into a clean string, including the source of each document for traceability.\n",
    "    findings = \"\\n\\n---\\n\\n\".join([f\"Source: {doc.metadata.get('source', 'N/A')}\\n\\n{doc.page_content}\" for doc in retrieved_docs])\n",
    "    print(f\"Retrieved {len(retrieved_docs)} documents.\")\n",
    "    print(f\"Sample Finding:\\n{findings[:500]}...\")\n",
    "    \n",
    "    # Return the findings in our standardized AgentOutput format.\n",
    "    return AgentOutput(agent_name=agent_name, findings=findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2fd555",
   "metadata": {},
   "source": [
    "Specifically checks if it's acting as the Medical Researcher and, if so, adjusts its retrieval parameter k based on the value in state['sop'].researcher_retriever_k. This makes the thoroughness of the literature search a dynamically tunable parameter that our AI Director can evolve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eed408",
   "metadata": {},
   "source": [
    "Now, let’s build our most technically complex specialist: the Patient Cohort Analyst. This agent will bridge the gap between unstructured RAG and structured data analytics. It will take a natural language request, use an LLM to translate it into a valid SQL query, and then execute that query against our DuckDB database of MIMIC-III data to provide a data-grounded feasibility estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "08446c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_cohort_analyst(task_description: str, state: GuildState) -> AgentOutput:\n",
    "    \"\"\"Estimates cohort size by generating and then executing a SQL query against the MIMIC database.\"\"\"\n",
    "    print(\"--- EXECUTING PATIENT COHORT ANALYST ---\")\n",
    "    \n",
    "    # This is a feature flag. We first check the SOP to see if this agent should even run.\n",
    "    if not state['sop'].use_sql_analyst:\n",
    "        print(\"SQL Analyst skipped as per SOP.\")\n",
    "        return AgentOutput(agent_name=\"Patient Cohort Analyst\", findings=\"Analysis skipped as per SOP.\")\n",
    "    \n",
    "    # For the LLM to write correct SQL, it needs to know the database schema.\n",
    "    # We connect to DuckDB and query the information_schema to get table and column names.\n",
    "    con = duckdb.connect(knowledge_stores['mimic_db_path'])\n",
    "    schema_query = \"\"\"\n",
    "    SELECT table_name, column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'main' ORDER BY table_name, column_name;\n",
    "    \"\"\"\n",
    "    schema = con.execute(schema_query).df()\n",
    "    con.close()\n",
    "    \n",
    "    # We create a highly detailed prompt for our SQL-writing LLM.\n",
    "    # It includes the schema and, crucially, specific instructions on how to map medical concepts to ICD9 codes or lab values.\n",
    "    sql_generation_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"You are an expert SQL writer specializing in DuckDB. Your task is to write a single, valid SQL query to count unique patients based on a request. The database contains MIMIC-III patient data with the following schema:\\n{schema.to_string()}\\n\\nIMPORTANT: All column names in your query MUST be uppercase (e.g., SELECT SUBJECT_ID, ICD9_CODE...).\\n\\nKey Mappings:\\n- T2DM (Type 2 Diabetes) corresponds to ICD9_CODE '25000'.\\n- Moderate renal impairment can be estimated by a creatinine lab value (ITEMID 50912) where VALUENUM is between 1.5 and 3.0.\\n- Uncontrolled T2D can be estimated by an HbA1c lab value (ITEMID 50852) where VALUENUM is greater than 8.0.\"),\n",
    "        (\"human\", \"Please write a SQL query to count the number of unique patients who meet the following criteria: {task}\")\n",
    "    ])\n",
    "    \n",
    "    # We create a simple chain to generate the SQL query.\n",
    "    sql_chain = sql_generation_prompt | llm_config['sql_coder'] | StrOutputParser()\n",
    "    \n",
    "    print(f\"Generating SQL for task: {task_description}\")\n",
    "    sql_query = sql_chain.invoke({\"task\": task_description})\n",
    "    # The LLM might wrap the query in markdown, so we clean it up.\n",
    "    sql_query = sql_query.strip().replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "    print(f\"Generated SQL Query:\\n{sql_query}\")\n",
    "    try:\n",
    "        # We now execute the generated query against the real DuckDB database.\n",
    "        con = duckdb.connect(knowledge_stores['mimic_db_path'])\n",
    "        result = con.execute(sql_query).fetchone()\n",
    "        patient_count = result[0] if result else 0\n",
    "        con.close()\n",
    "        \n",
    "        # We package the findings, including the query itself for transparency.\n",
    "        findings = f\"Generated SQL Query:\\n{sql_query}\\n\\nEstimated eligible patient count from the database: {patient_count}.\"\n",
    "        print(f\"Query executed successfully. Estimated patient count: {patient_count}\")\n",
    "    except Exception as e:\n",
    "        # If the SQL is invalid or the query fails, we handle the error gracefully.\n",
    "        findings = f\"Error executing SQL query: {e}. Defaulting to a count of 0.\"\n",
    "        print(f\"Error during query execution: {e}\")\n",
    "    return AgentOutput(agent_name=\"Patient Cohort Analyst\", findings=findings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003db599",
   "metadata": {},
   "source": [
    "The patient_cohort_analyst is our most advanced specialist. It's a full Text-to-SQL agent in a single function. The prompt engineering is the most critical part here. By providing the LLM with the exact database schema and the Key Mappings (e.g., how \"T2DM\" translates to ICD9_CODE '25000')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2691b714",
   "metadata": {},
   "source": [
    "With all our data-gathering specialists defined, we need the final agent in our system: the Criteria Synthesizer. This agent’s job is to act as the master writer. It will take the collected findings from all the other specialists and weave them into a single, coherent, and formally structured document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4affc91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criteria_synthesizer(state: GuildState) -> GuildState:\n",
    "    \"\"\"Synthesizes all the structured findings from the specialist agents into the final criteria document.\"\"\"\n",
    "    print(\"--- EXECUTING CRITERIA SYNTHESIZER ---\")\n",
    "    \n",
    "    # Retrieve the current SOP from the state.\n",
    "    sop = state['sop']\n",
    " \n",
    "    # Dynamically select the synthesizer model based on the SOP. This allows the Director to experiment with different models.\n",
    "    drafter_llm = get_hf_llm(\n",
    "        model_name=sop.synthesizer_model, \n",
    "        model_kwargs={\"temperature\": 0.2}\n",
    "    )\n",
    "\n",
    "    # We consolidate all the findings from the previous steps into a single, large context string.\n",
    "    # Each agent's findings are clearly demarcated.\n",
    "    context = \"\\n\\n---\\n\\n\".join([f\"**{out.agent_name} Findings:**\\n{out.findings}\" for out in state['agent_outputs']])\n",
    "    \n",
    "    # Construct the final prompt, combining the instructions from the SOP with the full context of findings.\n",
    "    prompt = f\"{sop.synthesizer_prompt}\\n\\n**Context from Specialist Teams:**\\n{context}\"\n",
    "    print(f\"Synthesizer is using model '{sop.synthesizer_model}'.\")\n",
    "    \n",
    "    # Invoke the drafter LLM to generate the final document.\n",
    "    response = drafter_llm.invoke(prompt)\n",
    "    print(\"Final criteria generated.\")\n",
    "    \n",
    "    # Return the final update to the state, populating the 'final_criteria' field.\n",
    "    return {**state, \"final_criteria\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a5fe95",
   "metadata": {},
   "source": [
    "It aggregates all the agent_outputs from the state into a comprehensive \"briefing packet\". A key feature is its dynamic model selection: drafter_llm = get_hf_llm(\n",
    "        model_name=sop.synthesizer_model, \n",
    "        model_kwargs={\"temperature\": 0.2}\n",
    "    ). \n",
    "    \n",
    "This means our AI Director can evolve the SOP to switch the synthesizer to a more powerful model (like llama3.1:8b-instruct) if it determines that the quality of the final draft is a key weakness. This makes the trade-off between drafting speed and quality an evolvable parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3d4110",
   "metadata": {},
   "source": [
    "### Orchestrating the Guild with LangGraph\n",
    "\n",
    "Now that we have defined all our individual agent nodes, we can now wire them together into a collaborative workflow using LangGraph. We will define a graph that first calls the Planner, then executes all the specialist tasks in parallel, and finally passes their collected findings to the Synthesizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a8ae9",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../figures/workflow.png\" width=\"1200\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "19173548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def specialist_execution_node(state: GuildState) -> GuildState:\n",
    "    \"\"\"This node acts as a dispatcher, executing all specialist tasks defined in the plan.\"\"\"\n",
    "    plan_tasks = state['plan']['plan']\n",
    "    outputs = []\n",
    "    \n",
    "    # We loop through each task in the plan generated by the Planner.\n",
    "    for task in plan_tasks:\n",
    "        agent_name = task['agent']\n",
    "        task_desc = task['task_description']\n",
    "        \n",
    "        # This is our routing logic. Based on the 'agent' name in the task, we call the appropriate function.\n",
    "        if \"Regulatory\" in agent_name:\n",
    "            output = retrieval_agent(task_desc, state, \"fda_retriever\", \"Regulatory Specialist\")\n",
    "        elif \"Medical\" in agent_name:\n",
    "            output = retrieval_agent(task_desc, state, \"pubmed_retriever\", \"Medical Researcher\")\n",
    "        elif \"Ethics\" in agent_name and state['sop'].use_ethics_specialist:\n",
    "            # We respect the 'use_ethics_specialist' feature flag from the SOP.\n",
    "            output = retrieval_agent(task_desc, state, \"ethics_retriever\", \"Ethics Specialist\")\n",
    "        elif \"Cohort\" in agent_name:\n",
    "            output = patient_cohort_analyst(task_desc, state)\n",
    "        else:\n",
    "            # If an agent is disabled or not recognized, we simply skip it.\n",
    "            continue\n",
    "        \n",
    "        outputs.append(output)\n",
    "    # We return the updated state with the list of all collected agent outputs.\n",
    "    return {**state, \"agent_outputs\": outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514e069",
   "metadata": {},
   "source": [
    "The specialist_execution_node takes the plan from the GuildState and orchestrates the execution of all the specialist tasks. The simple if/elif block acts as a router, dispatching each task to the correct agent function (our generic retrieval_agent or the specialized patient_cohort_analyst).\n",
    "\n",
    "This node also demonstrates the power of our SOP feature flags: it explicitly checks state['sop'].use_ethics_specialist before running that agent, allowing the AI Director to dynamically enable or disable capabilities.\n",
    "\n",
    "Now, we can finally build and compile the graph itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ab356a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "# We initialize a new StateGraph, telling it to use our GuildState as its schema.\n",
    "workflow = StateGraph(GuildState)\n",
    "\n",
    "# We add our three main functional units as nodes in the graph.\n",
    "workflow.add_node(\"planner\", planner_agent)\n",
    "workflow.add_node(\"execute_specialists\", specialist_execution_node)\n",
    "workflow.add_node(\"synthesizer\", criteria_synthesizer)\n",
    "\n",
    "# We define the control flow of the graph.\n",
    "# The entry point is the 'planner'.\n",
    "workflow.set_entry_point(\"planner\")\n",
    "\n",
    "# After the planner runs, the graph proceeds to the 'execute_specialists' node.\n",
    "workflow.add_edge(\"planner\", \"execute_specialists\")\n",
    "\n",
    "# After the specialists have all run, their outputs are passed to the 'synthesizer'.\n",
    "workflow.add_edge(\"execute_specialists\", \"synthesizer\")\n",
    "\n",
    "# After the synthesizer runs, the graph terminates.\n",
    "workflow.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# The compile() method turns our abstract graph definition into a runnable object.\n",
    "guild_graph = workflow.compile()\n",
    "print(\"Graph compiled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "778163c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see graph\n",
    "from IPython.display import display, Image\n",
    "\n",
    "Image(guild_graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8d1b2",
   "metadata": {},
   "source": [
    "#### Detailed graph\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../figures/agent_graph.png\" width=\"1200\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ec0be",
   "metadata": {},
   "source": [
    "### Testing our workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "90f48925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the full Guild graph with baseline SOP v1.0...\n",
      "--- EXECUTING PLANNER AGENT ---\n",
      "Planner Prompt:\n",
      "input_variables=['initial_request', 'planner_prompt'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['initial_request', 'planner_prompt'], input_types={}, partial_variables={'format_instructions': 'STRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only — do not include any backticks or Markdown in your output):\\n```\\n{\"properties\": {\"plan\": {\"description\": \"The plan to follow.\", \"items\": {}, \"title\": \"Plan\", \"type\": \"array\"}}, \"required\": [\"plan\"]}\\n```'}, template=\"{planner_prompt}\\n\\nTrial Concept: '{initial_request}'\\n\\n{format_instructions}\"), additional_kwargs={})]\n",
      "Generated Plan:\n",
      "{\n",
      "  \"plan\": [\n",
      "    {\n",
      "      \"agent\": \"Regulatory Specialist\",\n",
      "      \"task_description\": \"Review existing regulations and guidelines for Phase II trials of SGLT2 inhibitors and chronic kidney disease.\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Medical Researcher\",\n",
      "      \"task_description\": \"Draft a detailed protocol for the Phase II trial, including the objectives, design, and endpoints.\",\n",
      "      \"dependencies\": [\n",
      "        {\n",
      "          \"agent\": \"Regulatory Specialist\",\n",
      "          \"task_description\": \"Complete review of regulations and guidelines\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Ethics Specialist\",\n",
      "      \"task_description\": \"Evaluate the trial's potential risks and benefits, and ensure the trial complies with relevant ethics guidelines.\",\n",
      "      \"dependencies\": [\n",
      "        {\n",
      "          \"agent\": \"Medical Researcher\",\n",
      "          \"task_description\": \"Complete draft of the trial protocol\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Patient Cohort Analyst\",\n",
      "      \"task_description\": \"Conduct a thorough analysis of the target patient cohort, including demographics, disease characteristics, and potential inclusion/exclusion criteria.\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Regulatory Specialist\",\n",
      "      \"task_description\": \"Draft inclusion/exclusion criteria for the trial, based on input from the Medical Researcher and Ethics Specialist.\",\n",
      "      \"dependencies\": [\n",
      "        {\n",
      "          \"agent\": \"Ethics Specialist\",\n",
      "          \"task_description\": \"Complete evaluation of the trial's risks and benefits\"\n",
      "        },\n",
      "        {\n",
      "          \"agent\": \"Patient Cohort Analyst\",\n",
      "          \"task_description\": \"Complete analysis of the target patient cohort\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "--- EXECUTING REGULATORY SPECIALIST ---\n",
      "Task: Review existing regulations and guidelines for Phase II trials of SGLT2 inhibitors and chronic kidney disease.\n",
      "Retrieved 3 documents.\n",
      "Sample Finding:\n",
      "Source: data/fda_guidelines/fda_diabetes_guidance_ocr.txt\n",
      "\n",
      "NDA: 22-087 (Lamisil Oral Granules) 35 \n",
      "A.3 Primary Endpoint Results (PP) \n",
      "As a supportive analysis to the primary analysis, a subset of the mITT population who had no \n",
      "major protocol violations were included in the PP population. A list of major protocol violations \n",
      "‘was provided prior to database lock according to the statistical analysis plan. Major protocol \n",
      "violators were patients with the following criteria. \n",
      "o KOH result at week 1...\n",
      "--- EXECUTING MEDICAL RESEARCHER ---\n",
      "Task: Draft a detailed protocol for the Phase II trial, including the objectives, design, and endpoints.\n",
      "Using k=3 for retrieval.\n",
      "Retrieved 3 documents.\n",
      "Sample Finding:\n",
      "Source: data/pubmed_articles/36945734.txt\n",
      "\n",
      "Title: Effects of oral semaglutide on cardiovascular outcomes in individuals with type 2 diabetes and established atherosclerotic cardiovascular disease and/or chronic kidney disease: Design and baseline characteristics of SOUL, a randomized trial.\n",
      "\n",
      "---\n",
      "\n",
      "Source: data/pubmed_articles/40327845.txt\n",
      "\n",
      "Title: Rapid and Simultaneous Initiation of Guideline-Directed Kidney Therapies in Patients with CKD and Type 2 Diabetes.\n",
      "\n",
      "---\n",
      "\n",
      "Source: data/pubmed_articles/38...\n",
      "--- EXECUTING ETHICS SPECIALIST ---\n",
      "Task: Evaluate the trial's potential risks and benefits, and ensure the trial complies with relevant ethics guidelines.\n",
      "Retrieved 2 documents.\n",
      "Sample Finding:\n",
      "Source: data/ethical_guidelines/belmont_summary.txt\n",
      "\n",
      "3. Justice: This principle concerns the fairness of distribution of the burdens and benefits of research. The selection of research subjects must be equitable. Criteria should not be designed to exclude certain groups without a sound scientific or safety-related justification. For example, excluding participants based on race, gender, or socioeconomic status is unjust unless there is a clear rationale related to the drug's mechanism or risk pr...\n",
      "--- EXECUTING PATIENT COHORT ANALYST ---\n",
      "Generating SQL for task: Conduct a thorough analysis of the target patient cohort, including demographics, disease characteristics, and potential inclusion/exclusion criteria.\n",
      "Generated SQL Query:\n",
      "To count the number of unique patients who meet the specified criteria, we need to join multiple tables from the MIMIC-III database and filter based on the given conditions. Below is the SQL query to achieve this:\n",
      "\n",
      "\n",
      "SELECT COUNT(DISTINCT H.HADM_ID) AS UNIQUE_PATIENT_COUNT\n",
      "FROM ADMISSIONS H\n",
      "JOIN DIAGNOSES_ICD D ON H.HADM_ID = D.HADM_ID\n",
      "JOIN LABEVENTS L ON H.SUBJECT_ID = L.SUBJECT_ID AND H.HADM_ID = L.HADM_ID\n",
      "JOIN CHARTEVENTS C ON H.SUBJECT_ID = C.SUBJECT_ID AND H.HADM_ID = C.HADM_ID\n",
      "WHERE D.ICD9_CODE = '25000' -- T2DM\n",
      "AND (L.ITEMID = 50912 AND L.VALUENUM BETWEEN 1.5 AND 3.0) -- Moderate renal impairment\n",
      "AND (C.ITEMID = 50852 AND C.VALUEUOM = 'MMOL/L' AND C.VALUE > 8.0) -- Uncontrolled T2D\n",
      "AND C.VALUENUM IS NOT NULL\n",
      "AND L.VALUENUM IS NOT NULL;\n",
      "\n",
      "\n",
      "### Explanation:\n",
      "1. **JOIN ADMISSIONS, DIAGNOSES_ICD, LABEVENTS, and CHARTEVENTS**: \n",
      "   - `ADMISSIONS` table provides patient admission details.\n",
      "   - `DIAGNOSES_ICD` table contains ICD9 codes for diagnoses.\n",
      "   - `LABEVENTS` table contains laboratory results.\n",
      "   - `CHARTEVENTS` table contains continuous chart events like lab values.\n",
      "\n",
      "2. **Filtering Conditions**:\n",
      "   - `D.ICD9_CODE = '25000'`: Ensures that only patients with T2DM are included.\n",
      "   - `(L.ITEMID = 50912 AND L.VALUENUM BETWEEN 1.5 AND 3.0)`: Ensures that the patient has moderate renal impairment.\n",
      "   - `(C.ITEMID = 50852 AND C.VALUEUOM = 'MMOL/L' AND C.VALUE > 8.0)`: Ensures that the patient has uncontrolled T2D based on HbA1c levels.\n",
      "   - `C.VALUENUM IS NOT NULL` and `L.VALUENUM IS NOT NULL`: Ensures that only non-null values are considered.\n",
      "\n",
      "3. **Count Unique Patients**\n",
      "Error during query execution: Parser Error: syntax error at or near \"To\"\n",
      "\n",
      "LINE 1: To count the number of unique patients who meet the specified...\n",
      "        ^\n",
      "--- EXECUTING REGULATORY SPECIALIST ---\n",
      "Task: Draft inclusion/exclusion criteria for the trial, based on input from the Medical Researcher and Ethics Specialist.\n",
      "Retrieved 3 documents.\n",
      "Sample Finding:\n",
      "Source: data/fda_guidelines/fda_diabetes_guidance_ocr.txt\n",
      "\n",
      "Contents \n",
      "1 EXECUTIVE SUMMARY 4 \n",
      "1.1 Conclusions and Recommendations 4 \n",
      "1.2 Brief Overview of Clinical Studies 5 \n",
      "1.3 Statistical Issues and Findings . . . . . ... .................... 5 \n",
      "2 INTRODUCTION 6 \n",
      "21 OVerview. . . ... ... 7 \n",
      "2.2 DataSources . . ... ... 7 \n",
      "3 STATISTICAL EVALUATION 8 \n",
      "3.1 Evaluationof Efficacy . ... ................. ... ... ... 8 \n",
      "3.1.1 Study Design - .. 8 \n",
      "312 Endpoints4“..“‘......,...4,“.,» ........... 9 \n",
      "3.1.3...\n",
      "--- EXECUTING CRITERIA SYNTHESIZER ---\n",
      "Synthesizer is using model 'Qwen/Qwen2.5-7B-Instruct'.\n",
      "Final criteria generated.\n",
      "\n",
      "Final Guild Output:\n",
      "---------------------\n",
      "### Inclusion Criteria\n",
      "\n",
      "1. **Age**: Participants must be between 18 and 80 years old.\n",
      "2. **Gender**: No specific gender restrictions.\n",
      "3. **Race**: No specific racial restrictions.\n",
      "4. **Country**: Participants must be from the United States or have been enrolled in the clinical trials conducted outside the US.\n",
      "5. **Baseline Prognostic Factors**: Participants must have similar baseline characteristics across the mITT population, including demographics and prognostic factors, ensuring balanced treatment groups.\n",
      "\n",
      "### Exclusion Criteria\n",
      "\n",
      "1. **Major Protocol Violations**:\n",
      "   - Missing KOH result at week 10 visit.\n",
      "   - Missing culture result at week 10 visit.\n",
      "   - Failure to take >80% of the study drug as prescribed, either in terms of number of days dosed or amount of the dose taken.\n",
      "   - Receipt of wrong study treatment throughout the study.\n",
      "   - Receipt of wrong dose of study drug throughout the study.\n",
      "   - Switching of study drug to a different arm for more than 50% of the trial duration.\n",
      "   \n",
      "2. **Safety Concerns**: Participants with any significant safety concerns that may affect the integrity of the study results.\n",
      "3. **Contraindications**: Participants with known contraindications to the study drug.\n",
      "4. **Pregnancy/Lactation**: Pregnant or lactating women are excluded.\n",
      "5. **Severe Cognitive Impairment**: Individuals with severe cognitive impairments that may affect their ability to provide informed consent or comply with the study protocol.\n",
      "6. **Vulnerable Populations**: Individuals who are economically disadvantaged, prisoners, or those with severe cognitive impairments are excluded unless the research is directly intended to benefit these populations.\n",
      "7. **Other Medical Conditions**: Participants with other medical conditions that may interfere with the study objectives or pose additional risks.\n",
      "\n",
      "These criteria ensure that the study population is representative and that the results can be accurately interpreted.\n"
     ]
    }
   ],
   "source": [
    "# This is our high-level request, the initial spark for the entire workflow.\n",
    "test_request = \"Draft inclusion/exclusion criteria for a Phase II trial of 'Sotagliflozin', a novel SGLT2 inhibitor, for adults with uncontrolled Type 2 Diabetes (HbA1c > 8.0%) and moderate chronic kidney disease (CKD Stage 3).\"\n",
    "\n",
    "print(\"Running the full Guild graph with baseline SOP v1.0...\")\n",
    "# We prepare the initial state for the graph, providing the request and our baseline SOP.\n",
    "graph_input = {\n",
    "    \"initial_request\": test_request,\n",
    "    \"sop\": baseline_sop\n",
    "}\n",
    "# We invoke the compiled graph with the initial state. LangGraph will now execute the full workflow.\n",
    "final_result = guild_graph.invoke(graph_input)\n",
    "# After the graph finishes, we print the final, synthesized output.\n",
    "print(\"\\nFinal Guild Output:\")\n",
    "print(\"---------------------\")\n",
    "print(final_result['final_criteria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759b9152",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Foe evaluation, we need to move beyond simplistic, single-score metrics like accuracy. The quality of a clinical trial protocol is multi-dimensional. We will now build a sophisticated evaluation suite that is going to measure the Guild output across the five competing pillars we identified at the start. This gauntlet will provide the rich, multi-dimensional feedback signal that is the lifeblood of our evolutionary outer loop.\n",
    "\n",
    "In this section, here’s what we are going to do:\n",
    "\n",
    "- Implement LLM-as-a-Judge: We will build three separate evaluators using our most powerful model (llama3:70b) to act as expert judges for the qualitative aspects of Scientific Rigor, Regulatory Compliance, and Ethical Soundness.\n",
    "\n",
    "- Create Programmatic Evaluators: We will write two fast, reliable, and objective programmatic functions to score the quantitative aspects of Recruitment Feasibility and Operational Simplicity.\n",
    "\n",
    "- Build the Aggregate Evaluator: Wrapping all five of these individual evaluators into a single, master function that takes the final output of our Guild and generates the 5D performance vector our AI Director will use to make its decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a0dcd",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../figures/evaluation.png\" width=\"800\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b32059",
   "metadata": {},
   "source": [
    "First, a small utility: we will define a Pydantic model to ensure the output of our LLM judges is always structured, containing both a numerical score and a textual justification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cf08c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GradedScore(BaseModel):\n",
    "    \"\"\"A Pydantic model to structure the output of our LLM-as-a-Judge evaluators.\"\"\"\n",
    "    # The score must be a float between 0.0 and 1.0.\n",
    "    score: float = Field(description=\"A score from 0.0 to 1.0\")\n",
    "    # The reasoning provides the qualitative justification for the score, which is invaluable for debugging.\n",
    "    reasoning: str = Field(description=\"A brief justification for the score.\")\n",
    "\n",
    "output_parser = JsonOutputParser(\n",
    "        name=\"evaluator\",\n",
    "        pydantic_object=GradedScore\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f407b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Evaluator 1: Scientific Rigor (LLM-as-Judge)\n",
    "def scientific_rigor_evaluator(generated_criteria: str, pubmed_context: str) -> GradedScore:\n",
    "    \"\"\"Evaluates if the generated criteria are scientifically justified by the provided literature.\"\"\"\n",
    "    # We use our most powerful 'director' model for this nuanced evaluation task.\n",
    "    # Make sure to instruct the LLM to format its response according to our Pydantic model.\n",
    "    evaluator_llm = llm_config['director']\n",
    "    \n",
    "    # The prompt gives the LLM a specific persona (\"expert clinical scientist\") and a clear task.\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert clinical scientist. Evaluate a set of clinical trial criteria based on the provided scientific literature. A score of 1.0 means the criteria are perfectly aligned with and justified by the literature. A score of 0.0 means they contradict or ignore the literature.\\n\\n{format_instructions}\"),\n",
    "        # We provide both the criteria to be judged and the evidence it should be judged against.\n",
    "        (\"human\", \"Evaluate the following criteria:\\n\\n**Generated Criteria:**\\n{criteria}\\n\\n**Supporting Scientific Context:**\\n{context}\")\n",
    "    ]).partial(format_instructions=output_parser.get_format_instructions())\n",
    "    \n",
    "    # We create a simple LangChain Expression Language (LCEL) chain.\n",
    "    chain = prompt | evaluator_llm | output_parser\n",
    "    # We invoke the chain with the generated criteria and the context retrieved by the Medical Researcher.\n",
    "    return chain.invoke({\"criteria\": generated_criteria, \"context\": pubmed_context})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1c8845fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator 2: Regulatory Compliance (LLM-as-Judge)\n",
    "def regulatory_compliance_evaluator(generated_criteria: str, fda_context: str) -> GradedScore:\n",
    "    \"\"\"Evaluates if the generated criteria adhere to the provided FDA guidelines.\"\"\"\n",
    "    evaluator_llm = llm_config['director']\n",
    "    # This prompt assigns a different persona: \"expert regulatory affairs specialist\".\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert regulatory affairs specialist. Evaluate if a set of clinical trial criteria adheres to the provided FDA guidelines. A score of 1.0 means full compliance.\\n\\n{format_instructions}\"),\n",
    "        (\"human\", \"Evaluate the following criteria:\\n\\n**Generated Criteria:**\\n{criteria}\\n\\n**Applicable FDA Guidelines:**\\n{context}\")\n",
    "    ]).partial(format_instructions=output_parser.get_format_instructions())\n",
    "    \n",
    "    chain = prompt | evaluator_llm | output_parser\n",
    "    # This time, we invoke the chain with the context retrieved by the Regulatory Specialist.\n",
    "    return chain.invoke({\"criteria\": generated_criteria, \"context\": fda_context})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6bacb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator 3: Ethical Soundness (LLM-as-Judge)\n",
    "def ethical_soundness_evaluator(generated_criteria: str, ethics_context: str) -> GradedScore:\n",
    "    \"\"\"Evaluates if the criteria adhere to the core principles of clinical research ethics.\"\"\"\n",
    "    evaluator_llm = llm_config['director']\n",
    "    # The persona is now an \"expert on clinical trial ethics\".\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert on clinical trial ethics. Evaluate if a set of criteria adheres to the ethical principles provided (summarizing the Belmont Report). A score of 1.0 means the criteria show strong respect for persons, beneficence, and justice.\\n\\n{format_instructions}\"),\n",
    "        (\"human\", \"Evaluate the following criteria:\\n\\n**Generated Criteria:**\\n{criteria}\\n\\n**Ethical Principles:**\\n{context}\")\n",
    "    ]).partial(format_instructions=output_parser.get_format_instructions())\n",
    "    \n",
    "    chain = prompt | evaluator_llm | output_parser\n",
    "    # We use the context from the Ethics Specialist's retriever.\n",
    "    return chain.invoke({\"criteria\": generated_criteria, \"context\": ethics_context})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c4d0b0",
   "metadata": {},
   "source": [
    "Now, we will move on to our programmatic evaluators. Not all metrics require the nuanced reasoning of an LLM. For objective, quantifiable aspects, simple Python functions are faster, cheaper, and 100% reliable. Let’s build the evaluator for Recruitment Feasibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ae8e697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator 4: Recruitment Feasibility (Programmatic)\n",
    "def feasibility_evaluator(cohort_analyst_output: AgentOutput) -> GradedScore:\n",
    "    \"\"\"Scores feasibility by parsing the patient count from the SQL Analyst's output and normalizing it.\"\"\"\n",
    "    # We get the raw text findings from the Patient Cohort Analyst.\n",
    "    findings_text = cohort_analyst_output.findings\n",
    "    try:\n",
    "        # We parse the patient count from the analyst's formatted string.\n",
    "        count_str = findings_text.split(\"database: \")[1].replace('.', '')\n",
    "        patient_count = int(count_str)\n",
    "    except (IndexError, ValueError):\n",
    "        # If parsing fails, we return a score of 0.0, as the feasibility is unknown.\n",
    "        return GradedScore(score=0.0, reasoning=\"Could not parse patient count from analyst output.\")\n",
    "    \n",
    "    # We normalize the score against an ideal target. For a Phase II trial, ~150 patients is a reasonable goal.\n",
    "    IDEAL_COUNT = 150.0\n",
    "    # The score is the ratio of found patients to the ideal count, capped at 1.0.\n",
    "    score = min(1.0, patient_count / IDEAL_COUNT)\n",
    "    reasoning = f\"Estimated {patient_count} eligible patients. Score is normalized against an ideal target of {int(IDEAL_COUNT)}.\"\n",
    "    return GradedScore(score=score, reasoning=reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "975cfbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator 5: Operational Simplicity (Programmatic)\n",
    "def simplicity_evaluator(generated_criteria: str) -> GradedScore:\n",
    "    \"\"\"Scores simplicity by penalizing the inclusion of expensive or complex screening tests.\"\"\"\n",
    "    # We define a list of keywords for tests that add significant cost and complexity to patient screening.\n",
    "    EXPENSIVE_TESTS = [\"mri\", \"genetic sequencing\", \"pet scan\", \"biopsy\", \"echocardiogram\", \"endoscopy\"]\n",
    "    \n",
    "    # We count how many of these keywords appear in the generated criteria (case-insensitive).\n",
    "    test_count = sum(1 for test in EXPENSIVE_TESTS if test in generated_criteria.lower())\n",
    "    \n",
    "    # The score starts at 1.0 and is penalized by 0.5 for each expensive test found.\n",
    "    score = max(0.0, 1.0 - (test_count * 0.5))\n",
    "    reasoning = f\"Found {test_count} expensive/complex screening procedures mentioned.\"\n",
    "    return GradedScore(score=score, reasoning=reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e820e26",
   "metadata": {},
   "source": [
    "The simplicity_evaluator is a simple but effective heuristic for estimating operational cost. It acts as a \"red flag\" system. By scanning for keywords related to expensive procedures, it provides a penalty for criteria that might be scientifically sound but impractical to implement on a large scale. This provides another crucial, real-world constraint for our optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97fa47",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../figures/aggregate_evaluator.png\" width=\"1000\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d5472808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationResult(BaseModel):\n",
    "    \"\"\"A Pydantic model to hold the complete 5D evaluation result.\"\"\"\n",
    "    rigor: GradedScore\n",
    "    compliance: GradedScore\n",
    "    ethics: GradedScore\n",
    "    feasibility: GradedScore\n",
    "    simplicity: GradedScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dd727f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_evaluation(guild_final_state: GuildState) -> EvaluationResult:\n",
    "    \"\"\"Orchestrates the entire evaluation process, calling each of the five specialist evaluators.\"\"\"\n",
    "    print(\"--- RUNNING FULL EVALUATION GAUNTLET ---\")\n",
    "    \n",
    "    # Extract the necessary pieces of information from the final state of the Guild graph.\n",
    "    final_criteria = guild_final_state['final_criteria']\n",
    "    agent_outputs = guild_final_state['agent_outputs']\n",
    "    \n",
    "    # We need to find the specific findings from each specialist to pass to the correct evaluator.\n",
    "    # We use next() with a default value to safely handle cases where an agent might not have run.\n",
    "    pubmed_context = next((o.findings for o in agent_outputs if o.agent_name == \"Medical Researcher\"), \"\")\n",
    "    fda_context = next((o.findings for o in agent_outputs if o.agent_name == \"Regulatory Specialist\"), \"\")\n",
    "    ethics_context = next((o.findings for o in agent_outputs if o.agent_name == \"Ethics Specialist\"), \"\")\n",
    "    analyst_output = next((o for o in agent_outputs if o.agent_name == \"Patient Cohort Analyst\"), None)\n",
    "    \n",
    "    # We now call each of our five evaluator functions in sequence.\n",
    "    print(\"Evaluating: Scientific Rigor...\")\n",
    "    rigor = scientific_rigor_evaluator(final_criteria, pubmed_context)\n",
    "    print(\"Evaluating: Regulatory Compliance...\")\n",
    "    compliance = regulatory_compliance_evaluator(final_criteria, fda_context)\n",
    "    print(\"Evaluating: Ethical Soundness...\")\n",
    "    ethics = ethical_soundness_evaluator(final_criteria, ethics_context)\n",
    "    print(\"Evaluating: Recruitment Feasibility...\")\n",
    "    feasibility = feasibility_evaluator(analyst_output) if analyst_output else GradedScore(score=0, reasoning=\"Analyst did not run.\")\n",
    "    print(\"Evaluating: Operational Simplicity...\")\n",
    "    simplicity = simplicity_evaluator(final_criteria)\n",
    "    \n",
    "    print(\"--- EVALUATION GAUNTLET COMPLETE ---\")\n",
    "    # Finally, we package all the results into our EvaluationResult model.\n",
    "    return EvaluationResult(rigor=rigor, compliance=compliance, ethics=ethics, feasibility=feasibility, simplicity=simplicity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2b4e6b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING FULL EVALUATION GAUNTLET ---\n",
      "Evaluating: Scientific Rigor...\n",
      "Evaluating: Regulatory Compliance...\n",
      "Evaluating: Ethical Soundness...\n",
      "Evaluating: Recruitment Feasibility...\n",
      "Evaluating: Operational Simplicity...\n",
      "--- EVALUATION GAUNTLET COMPLETE ---\n",
      "\n",
      "Full Evaluation Result for Baseline SOP:\n",
      "{\n",
      "    \"rigor\": {\n",
      "        \"score\": 0.8,\n",
      "        \"reasoning\": \"The generated criteria are mostly aligned with the scientific literature, but some aspects ignore or contradict the provided studies. The inclusion criteria are generally reasonable, but the exclusion criteria contain some vague or overly broad restrictions (e.g., 'Safety Concerns', 'Other Medical Conditions'). The literature does not provide clear justifications for these criteria. Additionally, the criteria do not specifically address the populations mentioned in the supporting studies, such as individuals with type 2 diabetes and chronic kidney disease.\"\n",
      "    },\n",
      "    \"compliance\": {\n",
      "        \"score\": 0.9,\n",
      "        \"reasoning\": \"The generated criteria mostly adhere to the provided FDA guidelines, with some minor deviations. The inclusion criteria are in line with the guidelines, but the exclusion criteria could be more specific and detailed, especially regarding safety concerns and contraindications. The major protocol violations listed are consistent with the FDA guidance. Overall, the criteria demonstrate a good understanding of the FDA guidelines, but some refinements are needed to ensure full compliance.\"\n",
      "    },\n",
      "    \"ethics\": {\n",
      "        \"score\": 0.9,\n",
      "        \"reasoning\": \"The criteria generally adhere to the ethical principles of respect for persons, beneficence, and justice. Inclusion criteria are designed to ensure a representative study population, and exclusion criteria are primarily centered around safety concerns, protocol adherence, and contraindications to the study drug. However, the exclusion of vulnerable populations (economically disadvantaged, prisoners, or those with severe cognitive impairments) without a clear scientific or safety-related justification raises some concerns regarding the principle of justice. Overall, the criteria demonstrate a strong respect for persons and beneficence but could be improved in terms of justice.\"\n",
      "    },\n",
      "    \"feasibility\": {\n",
      "        \"score\": 0.0,\n",
      "        \"reasoning\": \"Could not parse patient count from analyst output.\"\n",
      "    },\n",
      "    \"simplicity\": {\n",
      "        \"score\": 1.0,\n",
      "        \"reasoning\": \"Found 0 expensive/complex screening procedures mentioned.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 'final_result' is the variable holding the final state from our test run in section 2.4.\n",
    "baseline_evaluation_result = run_full_evaluation(final_result)\n",
    "\n",
    "print(\"\\nFull Evaluation Result for Baseline SOP:\")\n",
    "# We use .dict() to get a dictionary representation of the Pydantic model for pretty printing.\n",
    "print(json.dumps(baseline_evaluation_result.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d592dbc",
   "metadata": {},
   "source": [
    "### Checking feasability issues\n",
    "\n",
    "There might be an SQL error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "19a6ff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing SQL query: Parser Error: syntax error at or near \"To\"\n",
      "\n",
      "LINE 1: To count the number of unique patients who meet the specified...\n",
      "        ^. Defaulting to a count of 0.\n"
     ]
    }
   ],
   "source": [
    "for a in final_result[\"agent_outputs\"]:\n",
    "    if a.agent_name == \"Patient Cohort Analyst\":\n",
    "        print(a.findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90090486",
   "metadata": {},
   "source": [
    "This is the precise, actionable, multi-dimensional feedback our AI Research Director needs. It has not just been told the output is “bad”, it has been told exactly which dimension is failing and why. The stage is now perfectly set for next part, where the Director will analyze this very report and attempt to evolve the SOP to fix this specific feasibility problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fad9b",
   "metadata": {},
   "source": [
    "Now, we are going to build the brain of our self-improving system: the “AI Research Director”. This is our “Outer Loop”. It’s a higher-level agentic system whose job is not to design clinical trials, but to improve the process of designing clinical trials.\n",
    "\n",
    "It will analyze the 5D performance vector from our evaluation gauntlet, diagnose the root cause of any weaknesses, and intelligently rewrite the Guild’s own GuildSOP to address them. This is where we implement the core evolutionary concepts that allow our system to learn and adapt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5261a654",
   "metadata": {},
   "source": [
    "Now, we do the following:\n",
    "\n",
    "- Create the Gene Pool: We will build a simple class to store and manage our evolving SOPs and their performance scores, creating a “gene pool” of process configurations.\n",
    "\n",
    "- Design the Director-Level Agents: We will implement the two core agents of the Director: the Performance Diagnostician, which identifies weaknesses, and the SOP Architect, which proposes solutions.\n",
    "\n",
    "- Architect the Evolutionary Loop: Then define a master function that orchestrates a single, complete generation of evolution: Diagnose -> Evolve -> Evaluate.\n",
    "\n",
    "- Run a Full Evolution Cycle: Going to execute this loop to show the system autonomously identifying the feasibility weakness in our baseline SOP and generating new, mutated SOPs to try and fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd916895",
   "metadata": {},
   "source": [
    "### Managing Guild Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d7459036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOPGenePool:\n",
    "    \"\"\"A simple class to store and manage a collection of GuildSOPs and their evaluations, acting as our 'gene pool'.\"\"\"\n",
    "    def __init__(self):\n",
    "        # The pool will be a list of dictionaries, each holding an SOP, its evaluation, and metadata.\n",
    "        self.pool: List[Dict[str, Any]] = []\n",
    "        # A simple counter to assign a unique version number to each new SOP.\n",
    "        self.version_counter = 0\n",
    "\n",
    "    def add(self, sop: GuildSOP, eval_result: EvaluationResult, parent_version: Optional[int] = None):\n",
    "        \"\"\"Adds a new SOP and its evaluation result to the pool.\"\"\"\n",
    "        self.version_counter += 1\n",
    "        entry = {\n",
    "            \"version\": self.version_counter,\n",
    "            \"sop\": sop,\n",
    "            \"evaluation\": eval_result,\n",
    "            \"parent\": parent_version # Tracking the parent is key for analyzing evolutionary paths.\n",
    "        }\n",
    "        self.pool.append(entry)\n",
    "        print(f\"Added SOP v{self.version_counter} to the gene pool.\")\n",
    "        \n",
    "    def get_latest_entry(self) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"A convenience method to retrieve the most recently added entry.\"\"\"\n",
    "        return self.pool[-1] if self.pool else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c673f0b0",
   "metadata": {},
   "source": [
    "### Building The Director-Level Agents\n",
    "\n",
    "Now we define the two agents that form the core of our evolution engine. These agents operate at a higher level of abstraction. They don’t reason about medicine or regulations, they reason about process and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2ff19",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../figures/director_level_agents.png\" width=\"600\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f767d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diagnosis(BaseModel):\n",
    "    \"\"\"A Pydantic model for the structured output of the Diagnostician agent.\"\"\"\n",
    "    # The primary weakness must be one of the five pillars.\n",
    "    primary_weakness: Literal['rigor', 'compliance', 'ethics', 'feasibility', 'simplicity']\n",
    "    # A detailed analysis of why the weakness occurred, grounding its reasoning in the specific scores.\n",
    "    root_cause_analysis: str = Field(description=\"A detailed analysis of why the weakness occurred, referencing specific scores.\")\n",
    "    # A high-level, strategic recommendation for how to fix the problem.\n",
    "    recommendation: str = Field(description=\"A high-level recommendation for how to modify the SOP to address the weakness.\")\n",
    "\n",
    "\n",
    "def performance_diagnostician(eval_result: EvaluationResult) -> Diagnosis:\n",
    "    \"\"\"Analyzes the 5D evaluation vector and diagnoses the primary weakness.\"\"\"\n",
    "    print(\"--- EXECUTING PERFORMANCE DIAGNOSTICIAN ---\")\n",
    "    # We use our most powerful 'director' model (Llama 3 70B) for this critical reasoning task.\n",
    "    diagnostician_llm = llm_config['director']\n",
    "\n",
    "    dir_output_parser = JsonOutputParser(\n",
    "        name=\"dir_parser\",\n",
    "        pydantic_object=Diagnosis\n",
    "    )\n",
    "    # The prompt assigns the persona of a management consultant specializing in process optimization.\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a world-class management consultant specializing in process optimization. Your task is to analyze a performance scorecard and identify the single biggest weakness. Then, provide a root cause analysis and a strategic recommendation.\\n\\n{format_instructions}\"),\n",
    "        (\"human\", \"Please analyze the following performance evaluation report:\\n\\n{report}\")\n",
    "    ]).partial(format_instructions=dir_output_parser.get_format_instructions())\n",
    "    \n",
    "    chain = prompt | diagnostician_llm | dir_output_parser\n",
    "    # We invoke the chain with the JSON representation of the full evaluation result.\n",
    "    return chain.invoke({\"report\": eval_result.model_dump_json()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8efefa",
   "metadata": {},
   "source": [
    "The second agent is the SOP Architect. This agent is the evolver, It takes the diagnosis from the previous step and the current GuildSOP, and its job is to generate several new, mutated versions of the SOP, each representing a different strategy to solve the identified problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1ee8c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolvedSOPs(BaseModel):\n",
    "    \"\"\"A Pydantic container for a list of new, evolved GuildSOPs.\"\"\"\n",
    "    mutations: List[GuildSOP]\n",
    "\n",
    "def sop_architect(diagnosis: Diagnosis, current_sop: GuildSOP) -> EvolvedSOPs:\n",
    "    \"\"\"Takes a diagnosis and the current SOP, and generates a list of new, mutated SOPs to test.\"\"\"\n",
    "    print(\"--- EXECUTING SOP ARCHITECT ---\")\n",
    "    # We again use our powerful 'director' model, this time configured to output a list of GuildSOP objects.\n",
    "    architect_llm = llm_config['director']\n",
    "    evolver_output_parser = JsonOutputParser(\n",
    "        name=\"evolver_parser\",\n",
    "        pydantic_object=EvolvedSOPs\n",
    "    )\n",
    "\n",
    "    # This prompt is highly specific. It tells the agent its job is to modify a JSON object (the SOP)\n",
    "    # to fix a specific problem. We even provide the JSON schema of the SOP in the prompt for context.\n",
    "    schema_str = json.dumps(GuildSOP.model_json_schema()).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are an AI process architect. Your job is to modify a process configuration (an SOP) to fix a diagnosed problem. \"\n",
    "     f\"The SOP is a JSON object with this schema: {schema_str}. \"\n",
    "     \"You must return a list of 2-3 new, valid SOP JSON objects under the 'mutations' key. \"\n",
    "     \"Propose diverse and creative mutations. For example, you can change prompts, toggle agents, change retrieval parameters, \"\n",
    "     \"or even change the model used for a task. Only modify fields relevant to the diagnosis.\\n\\n\"\n",
    "     \"{format_instructions}\"),  \n",
    "    (\"human\", \n",
    "     \"Here is the current SOP:\\n{current_sop}\\n\\n\"\n",
    "     \"Here is the performance diagnosis:\\n{diagnosis}\\n\\n\"\n",
    "     \"Based on the diagnosis, please generate 2-3 new, improved SOPs.\")\n",
    "    ]).partial(format_instructions=evolver_output_parser.get_format_instructions())\n",
    "    \n",
    "    chain = prompt | architect_llm | evolver_output_parser\n",
    "    return chain.invoke({\n",
    "    \"current_sop\": json.dumps(current_sop) if isinstance(current_sop, dict) else current_sop.model_dump_json(),\n",
    "    \"diagnosis\": json.dumps(diagnosis) if isinstance(diagnosis, dict) else diagnosis.model_dump_json(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd96612",
   "metadata": {},
   "source": [
    "1. The sop_architect is the creative engine of our self-improving system. Its prompt is a kind of instruction engineering. We are telling the LLM: \"You are a programmer. Here is the source code (current_sop). Here is the bug report (diagnosis). Now, write 2-3 different patches (mutations) to try and fix the bug\".\n",
    "\n",
    "2. By providing the GuildSOP.schema_json() directly in the prompt, we drastically increase the likelihood that the LLM will generate valid, correctly formatted new SOPs. This agent doesn't just randomly change things; it proposes targeted, intelligent modifications based on the specific problem identified by the diagnostician."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d4e1f",
   "metadata": {},
   "source": [
    "We can now wrap these into a master function that orchestrates one full cycle of Diagnose -> Evolve -> Evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "31fc8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolution_cycle(gene_pool: SOPGenePool, trial_request: str):\n",
    "    \"\"\"Runs one full cycle of diagnosis, mutation, and re-evaluation.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*25 + \" STARTING NEW EVOLUTION CYCLE \" + \"=\"*25)\n",
    "    \n",
    "    # Step 1: Select the current best SOP to improve upon. For simplicity, we'll just take the latest one added to the pool.\n",
    "    current_best_entry = gene_pool.get_latest_entry()\n",
    "    parent_sop = current_best_entry['sop']\n",
    "    parent_eval = current_best_entry['evaluation']\n",
    "    parent_version = current_best_entry['version']\n",
    "    print(f\"Improving upon SOP v{parent_version}...\")\n",
    "    \n",
    "    # Step 2: Diagnose the performance of the parent SOP.\n",
    "    diagnosis = performance_diagnostician(parent_eval)\n",
    "    print(f\"Diagnosis complete. Primary Weakness: '{diagnosis[\"primary_weakness\"]}'. Recommendation: {diagnosis[\"recommendation\"]}\")\n",
    "\n",
    "    # Step 3: Architect new SOP candidates based on the diagnosis.\n",
    "    new_sop_candidates = sop_architect(diagnosis, parent_sop)\n",
    "    print(f\"Generated {len(new_sop_candidates[\"mutations\"])} new SOP candidates.\")\n",
    "    # Step 4: Evaluate each new candidate by running the full Guild graph and the evaluation gauntlet.\n",
    "    for i, candidate_sop in enumerate(new_sop_candidates[\"mutations\"]):\n",
    "        print(f\"\\n--- Testing SOP candidate {i+1}/{len(new_sop_candidates[\"mutations\"])} ---\")\n",
    "        print(candidate_sop)\n",
    "        # We run the entire inner loop (the Guild) with the new, mutated SOP.\n",
    "        guild_input = {\"initial_request\": trial_request, \"sop\": GuildSOP(**candidate_sop)}\n",
    "        final_state = guild_graph.invoke(guild_input)\n",
    "        \n",
    "        # We then run our full evaluation gauntlet on the output.\n",
    "        eval_result = run_full_evaluation(final_state)\n",
    "        # Finally, we add the new SOP and its performance to our gene pool.\n",
    "        gene_pool.add(sop=candidate_sop, eval_result=eval_result, parent_version=parent_version)\n",
    "    print(\"\\n\" + \"=\"*25 + \" EVOLUTION CYCLE COMPLETE \" + \"=\"*26)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebeb62f",
   "metadata": {},
   "source": [
    "Let’s put it all together. We will initialize our SOPGenePool, add our baseline SOP and its evaluation result, and then run a single evolution cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "38069ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized SOP Gene Pool.\n",
      "Added SOP v1 to the gene pool.\n",
      "\n",
      "========================= STARTING NEW EVOLUTION CYCLE =========================\n",
      "Improving upon SOP v1...\n",
      "--- EXECUTING PERFORMANCE DIAGNOSTICIAN ---\n",
      "Diagnosis complete. Primary Weakness: 'feasibility'. Recommendation: Revise the criteria reporting format to ensure clear and concise presentation of patient count and other essential feasibility metrics, enabling efficient evaluation and decision-making.\n",
      "--- EXECUTING SOP ARCHITECT ---\n",
      "Generated 2 new SOP candidates.\n",
      "\n",
      "--- Testing SOP candidate 1/2 ---\n",
      "{'planner_prompt': \"You are a master planner for clinical trial design. Your task is to receive a high-level trial concept and break it down into a structured plan with specific sub-tasks for a team of specialists: a Regulatory Specialist, a Medical Researcher, an Ethics Specialist, and a Patient Cohort Analyst. Output a JSON object with a single key 'plan' containing a list of tasks. Each task must have 'agent', 'task_description', and 'dependencies' keys. Ensure the Patient Cohort Analyst task includes a 'patient_count' key in its output.\", 'researcher_retriever_k': 3, 'synthesizer_prompt': \"You are an expert medical writer. Your task is to synthesize the structured findings from all specialist teams into a formal 'Inclusion and Exclusion Criteria' document. Be concise, precise, and adhere strictly to the information provided. Structure your output into two sections: 'Inclusion Criteria' and 'Exclusion Criteria'. Also, extract and highlight the patient count from the analyst output and include it in the 'Feasibility Metrics' section.\", 'synthesizer_model': 'Qwen/Qwen2.5-7B-Instruct', 'use_sql_analyst': True, 'use_ethics_specialist': True}\n",
      "--- EXECUTING PLANNER AGENT ---\n",
      "Planner Prompt:\n",
      "input_variables=['initial_request', 'planner_prompt'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['initial_request', 'planner_prompt'], input_types={}, partial_variables={'format_instructions': 'STRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only — do not include any backticks or Markdown in your output):\\n```\\n{\"properties\": {\"plan\": {\"description\": \"The plan to follow.\", \"items\": {}, \"title\": \"Plan\", \"type\": \"array\"}}, \"required\": [\"plan\"]}\\n```'}, template=\"{planner_prompt}\\n\\nTrial Concept: '{initial_request}'\\n\\n{format_instructions}\"), additional_kwargs={})]\n",
      "Generated Plan:\n",
      "{\n",
      "  \"plan\": [\n",
      "    {\n",
      "      \"agent\": \"Regulatory Specialist\",\n",
      "      \"task_description\": \"Review existing clinical trial regulations and guidelines for conducting a Phase II trial in the United States and European Union.\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Medical Researcher\",\n",
      "      \"task_description\": \"Review the literature on Sotagliflozin and its use in treating Type 2 Diabetes and moderate CKD Stage 3.\",\n",
      "      \"dependencies\": [\n",
      "        \"Regulatory Specialist\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Ethics Specialist\",\n",
      "      \"task_description\": \"Review the trial concept for compliance with Institutional Review Board (IRB) and Ethics Committee requirements.\",\n",
      "      \"dependencies\": [\n",
      "        \"Regulatory Specialist\",\n",
      "        \"Medical Researcher\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Patient Cohort Analyst\",\n",
      "      \"task_description\": \"Develop a plan to identify and recruit a patient cohort for the trial, including estimating the number of patients with HbA1c > 8.0% and moderate CKD Stage 3.\",\n",
      "      \"dependencies\": [\n",
      "        \"Regulatory Specialist\",\n",
      "        \"Medical Researcher\",\n",
      "        \"Ethics Specialist\"\n",
      "      ],\n",
      "      \"patient_count\": 1000\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "--- EXECUTING REGULATORY SPECIALIST ---\n",
      "Task: Review existing clinical trial regulations and guidelines for conducting a Phase II trial in the United States and European Union.\n",
      "Retrieved 3 documents.\n",
      "Sample Finding:\n",
      "Source: data/fda_guidelines/fda_diabetes_guidance_ocr.txt\n",
      "\n",
      "\\\\Cdsesub1\\n22071\\N_000\\2006-09-08\\crt\\datasets. For the two pivotal Phase 3 studies \n",
      "the sponsor has submitted both raw data sets and derived data sets with thorough documen- \n",
      "tation on the derived data sets. In addition to the electronic data sets an annotated electronic \n",
      "CRF is submitted to define variable and data set location. At this time the data sets appear to \n",
      "be sufficient to assess the AE rates and efficacy of Lamisil Mini-tab...\n",
      "--- EXECUTING MEDICAL RESEARCHER ---\n",
      "Task: Review the literature on Sotagliflozin and its use in treating Type 2 Diabetes and moderate CKD Stage 3.\n",
      "Using k=3 for retrieval.\n",
      "Retrieved 3 documents.\n",
      "Sample Finding:\n",
      "Source: data/pubmed_articles/31101403.txt\n",
      "\n",
      "Title: Safety and Effectiveness of Bexagliflozin in Patients With Type 2 Diabetes Mellitus and Stage 3a/3b CKD.\n",
      "\n",
      "---\n",
      "\n",
      "Source: data/pubmed_articles/30697905.txt\n",
      "\n",
      "Abstract: AIM: The use of sodium glucose co-transporter 2 (SGLT2) inhibitors in patients with type 2 diabetes mellitus (T2DM) and chronic kidney disease (CKD) has been limited, primarily because glycaemic efficacy is dependent on kidney function. We performed a systematic review and meta-analysi...\n",
      "--- EXECUTING ETHICS SPECIALIST ---\n",
      "Task: Review the trial concept for compliance with Institutional Review Board (IRB) and Ethics Committee requirements.\n",
      "Retrieved 2 documents.\n",
      "Sample Finding:\n",
      "Source: data/ethical_guidelines/belmont_summary.txt\n",
      "\n",
      "3. Justice: This principle concerns the fairness of distribution of the burdens and benefits of research. The selection of research subjects must be equitable. Criteria should not be designed to exclude certain groups without a sound scientific or safety-related justification. For example, excluding participants based on race, gender, or socioeconomic status is unjust unless there is a clear rationale related to the drug's mechanism or risk pr...\n",
      "--- EXECUTING PATIENT COHORT ANALYST ---\n",
      "Generating SQL for task: Develop a plan to identify and recruit a patient cohort for the trial, including estimating the number of patients with HbA1c > 8.0% and moderate CKD Stage 3.\n",
      "Generated SQL Query:\n",
      "\n",
      "SELECT COUNT(DISTINCT SUBJECT_ID) AS UNIQUE_PATIENT_COUNT\n",
      "FROM mimic III.admissions a\n",
      "JOIN mimic III.icustays i ON a.SUBJECT_ID = i.SUBJECT_ID AND a.HADM_ID = i.HADM_ID\n",
      "JOIN mimic III.labevents l1 ON a.SUBJECT_ID = l1.SUBJECT_ID AND a.HADM_ID = l1.HADM_ID\n",
      "JOIN mimic III.labevents l2 ON a.SUBJECT_ID = l2.SUBJECT_ID AND a.HADM_ID = l2.HADM_ID\n",
      "WHERE l1.ITEMID = 50852 AND l1.VALUEUOM = 'PCT' AND l1.VALUENUM > 8.0\n",
      "AND l2.ITEMID = 50912 AND l2.VALUENUM BETWEEN 1.5 AND 3.0;\n",
      "\n",
      "\n",
      "### Explanation:\n",
      "- **mimic III.admissions (a)**: This table contains patient admission information.\n",
      "- **mimic III.icustays (i)**: This table contains ICU stay information, which we join with admissions to ensure that the lab results are from the same hospitalization.\n",
      "- **mimic III.labevents (l1)**: We join this table twice to capture different lab results.\n",
      "  - **l1**: Lab event for HbA1c, where the value is greater than 8.0%.\n",
      "  - **l2**: Lab event for creatinine, where the value is between 1.5 and 3.0, indicating moderate renal impairment.\n",
      "- **COUNT(DISTINCT SUBJECT_ID)**: Counts the number of unique patients who meet both criteria.\n",
      "\n",
      "### Notes:\n",
      "- Ensure that the table names and column names are correctly referenced according to your actual schema. Adjustments may be necessary if the actual table or column names differ.\n",
      "- The `VALUEUOM` condition for HbA1c ensures that the value is in percentage units (`PCT`).\n",
      "Error during query execution: Parser Error: syntax error at or near \".\"\n",
      "\n",
      "LINE 3: FROM mimic III.admissions a\n",
      "                      ^\n",
      "--- EXECUTING CRITERIA SYNTHESIZER ---\n",
      "Synthesizer is using model 'Qwen/Qwen2.5-7B-Instruct'.\n",
      "Final criteria generated.\n",
      "--- RUNNING FULL EVALUATION GAUNTLET ---\n",
      "Evaluating: Scientific Rigor...\n",
      "Evaluating: Regulatory Compliance...\n",
      "Evaluating: Ethical Soundness...\n",
      "Evaluating: Recruitment Feasibility...\n",
      "Evaluating: Operational Simplicity...\n",
      "--- EVALUATION GAUNTLET COMPLETE ---\n",
      "Added SOP v2 to the gene pool.\n",
      "\n",
      "--- Testing SOP candidate 2/2 ---\n",
      "{'planner_prompt': \"You are a master planner for clinical trial design. Your task is to receive a high-level trial concept and break it down into a structured plan with specific sub-tasks for a team of specialists: a Regulatory Specialist, a Medical Researcher, an Ethics Specialist, and a Patient Cohort Analyst. Output a JSON object with a single key 'plan' containing a list of tasks. Each task must have 'agent', 'task_description', and 'dependencies' keys. Ensure the Patient Cohort Analyst task includes a 'feasibility_metrics' key in its output, which contains 'patient_count', 'eligibility_rate', and 'enrollment_period' keys.\", 'researcher_retriever_k': 3, 'synthesizer_prompt': \"You are an expert medical writer. Your task is to synthesize the structured findings from all specialist teams into a formal 'Inclusion and Exclusion Criteria' document. Be concise, precise, and adhere strictly to the information provided. Structure your output into two sections: 'Inclusion Criteria' and 'Exclusion Criteria'. Also, extract and highlight the feasibility metrics (\"}\n",
      "--- EXECUTING PLANNER AGENT ---\n",
      "Planner Prompt:\n",
      "input_variables=['initial_request', 'planner_prompt'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['initial_request', 'planner_prompt'], input_types={}, partial_variables={'format_instructions': 'STRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only — do not include any backticks or Markdown in your output):\\n```\\n{\"properties\": {\"plan\": {\"description\": \"The plan to follow.\", \"items\": {}, \"title\": \"Plan\", \"type\": \"array\"}}, \"required\": [\"plan\"]}\\n```'}, template=\"{planner_prompt}\\n\\nTrial Concept: '{initial_request}'\\n\\n{format_instructions}\"), additional_kwargs={})]\n",
      "Generated Plan:\n",
      "{\n",
      "  \"plan\": [\n",
      "    {\n",
      "      \"agent\": \"Regulatory Specialist\",\n",
      "      \"task_description\": \"Review and ensure compliance with regulatory requirements for the Phase II trial of Sotagliflozin.\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Medical Researcher\",\n",
      "      \"task_description\": \"Develop the final inclusion/exclusion criteria for the trial based on the trial concept.\",\n",
      "      \"dependencies\": [\n",
      "        \"Regulatory Specialist\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Ethics Specialist\",\n",
      "      \"task_description\": \"Review the inclusion/exclusion criteria for compliance with ethics guidelines and regulations.\",\n",
      "      \"dependencies\": [\n",
      "        \"Medical Researcher\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"agent\": \"Patient Cohort Analyst\",\n",
      "      \"task_description\": \"Assess the feasibility of recruiting the required patient cohort for the trial.\",\n",
      "      \"dependencies\": [\n",
      "        \"Ethics Specialist\"\n",
      "      ],\n",
      "      \"feasibility_metrics\": {\n",
      "        \"patient_count\": \"Estimate the total number of patients that meet the inclusion/exclusion criteria.\",\n",
      "        \"eligibility_rate\": \"Calculate the percentage of patients that are eligible for the trial.\",\n",
      "        \"enrollment_period\": \"Determine the expected duration of patient enrollment for the trial.\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "--- EXECUTING REGULATORY SPECIALIST ---\n",
      "Task: Review and ensure compliance with regulatory requirements for the Phase II trial of Sotagliflozin.\n",
      "Retrieved 3 documents.\n",
      "Sample Finding:\n",
      "Source: data/fda_guidelines/fda_diabetes_guidance_ocr.txt\n",
      "\n",
      "\\\\Cdsesub1\\n22071\\N_000\\2006-09-08\\crt\\datasets. For the two pivotal Phase 3 studies \n",
      "the sponsor has submitted both raw data sets and derived data sets with thorough documen- \n",
      "tation on the derived data sets. In addition to the electronic data sets an annotated electronic \n",
      "CRF is submitted to define variable and data set location. At this time the data sets appear to \n",
      "be sufficient to assess the AE rates and efficacy of Lamisil Mini-tab...\n",
      "--- EXECUTING MEDICAL RESEARCHER ---\n",
      "Task: Develop the final inclusion/exclusion criteria for the trial based on the trial concept.\n",
      "Using k=3 for retrieval.\n",
      "Retrieved 3 documents.\n",
      "Sample Finding:\n",
      "Source: data/pubmed_articles/36945734.txt\n",
      "\n",
      "Title: Effects of oral semaglutide on cardiovascular outcomes in individuals with type 2 diabetes and established atherosclerotic cardiovascular disease and/or chronic kidney disease: Design and baseline characteristics of SOUL, a randomized trial.\n",
      "\n",
      "---\n",
      "\n",
      "Source: data/pubmed_articles/34817311.txt\n",
      "\n",
      "is critical in providing consistent and appropriate care for all patients. Strategies to improve outcomes should also include use of clear referral criteria, u...\n",
      "--- EXECUTING ETHICS SPECIALIST ---\n",
      "Task: Review the inclusion/exclusion criteria for compliance with ethics guidelines and regulations.\n",
      "Retrieved 2 documents.\n",
      "Sample Finding:\n",
      "Source: data/ethical_guidelines/belmont_summary.txt\n",
      "\n",
      "Title: Summary of the Belmont Report Principles for Clinical Research\n",
      "1. Respect for Persons: This principle requires that individuals be treated as autonomous agents and that persons with diminished autonomy are entitled to protection. This translates to robust informed consent processes. Inclusion/exclusion criteria must not unduly target or coerce vulnerable populations, such as economically disadvantaged individuals, prisoners, or those wi...\n",
      "--- EXECUTING PATIENT COHORT ANALYST ---\n",
      "Generating SQL for task: Assess the feasibility of recruiting the required patient cohort for the trial.\n",
      "Generated SQL Query:\n",
      "To count the number of unique patients who have a diagnosis of Type 2 Diabetes (T2DM), moderate renal impairment, and uncontrolled T2D, you can use the following SQL query:\n",
      "\n",
      "\n",
      "SELECT COUNT(DISTINCT SUBJECT_ID) AS UNIQUE_PATIENTS_COUNT\n",
      "FROM YOUR_TABLE_NAME\n",
      "WHERE ICD9_CODE = '25000'\n",
      "  AND EXISTS (\n",
      "    SELECT 1\n",
      "    FROM YOUR_TABLE_NAME AS T2\n",
      "    WHERE T2.SUBJECT_ID = YOUR_TABLE_NAME.SUBJECT_ID\n",
      "      AND T2.ITEMID = 50912\n",
      "      AND T2.VALUENUM BETWEEN 1.5 AND 3.0\n",
      "  )\n",
      "  AND EXISTS (\n",
      "    SELECT 1\n",
      "    FROM YOUR_TABLE_NAME AS T3\n",
      "    WHERE T3.SUBJECT_ID = YOUR_TABLE_NAME.SUBJECT_ID\n",
      "      AND T3.ITEMID = 50852\n",
      "      AND T3.VALUENUM > 8.0\n",
      "  );\n",
      "\n",
      "\n",
      "### Explanation:\n",
      "1. **Main Query**: The main query counts the distinct `SUBJECT_ID` to get the number of unique patients.\n",
      "2. **ICD9_CODE Condition**: The `WHERE ICD9_CODE = '25000'` condition ensures that only patients with a diagnosis of Type 2 Diabetes are considered.\n",
      "3. **Moderate Renal Impairment**: The `EXISTS` subquery checks for the presence of moderate renal impairment by looking for a creatinine lab value (ITEMID 50912) within the range of 1.5 to 3.0.\n",
      "4. **Uncontrolled T2D**: Another `EXISTS` subquery checks for the presence of an HbA1c lab value (ITEMID 50852) greater than 8.0, indicating uncontrolled T2D.\n",
      "\n",
      "Replace `YOUR_TABLE_NAME` with the actual table name in your database.\n",
      "Error during query execution: Parser Error: syntax error at or near \"To\"\n",
      "\n",
      "LINE 1: To count the number of unique patients who have a diagnosis...\n",
      "        ^\n",
      "--- EXECUTING CRITERIA SYNTHESIZER ---\n",
      "Synthesizer is using model 'Qwen/Qwen2.5-7B-Instruct'.\n",
      "Final criteria generated.\n",
      "--- RUNNING FULL EVALUATION GAUNTLET ---\n",
      "Evaluating: Scientific Rigor...\n",
      "Evaluating: Regulatory Compliance...\n",
      "Evaluating: Ethical Soundness...\n",
      "Evaluating: Recruitment Feasibility...\n",
      "Evaluating: Operational Simplicity...\n",
      "--- EVALUATION GAUNTLET COMPLETE ---\n",
      "Added SOP v3 to the gene pool.\n",
      "\n",
      "========================= EVOLUTION CYCLE COMPLETE ==========================\n"
     ]
    }
   ],
   "source": [
    "# Initialize our gene pool.\n",
    "gene_pool = SOPGenePool()\n",
    "print(\"Initialized SOP Gene Pool.\")\n",
    "\n",
    "# Add our baseline SOP (v1) and its previously calculated evaluation as the first entry.\n",
    "gene_pool.add(sop=baseline_sop, eval_result=baseline_evaluation_result)\n",
    "# Now, we execute one full cycle of evolution, starting from our baseline.\n",
    "run_evolution_cycle(gene_pool, test_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe18e2",
   "metadata": {},
   "source": [
    "In this final section, here’s what we are going to do:\n",
    "\n",
    "- Analyze the Gene Pool: We will first print a summary of all the SOPs and their performance scores to see the direct impact of the mutations.\n",
    "\n",
    "- Identify the Pareto Front: We will write a function to programmatically identify the non-dominated solutions in our gene pool the set of SOPs that represent the best possible trade-offs.\n",
    "\n",
    "- Visualize the Frontier: Create a powerful visualization, a parallel coordinates plot, that allows us to see the performance of our optimal SOPs across all five dimensions simultaneously, making the trade-offs clear and intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6f897d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOP Gene Pool Evaluation Summary:\n",
      "---------------------------------\n",
      "SOP v1  (Parent)      : Rigor=0.80, Compliance=0.90, Ethics=0.90, Feasibility=0.00, Simplicity=1.00\n",
      "SOP v2  (Child of v1) : Rigor=0.80, Compliance=0.75, Ethics=0.90, Feasibility=0.00, Simplicity=1.00\n",
      "SOP v3  (Child of v1) : Rigor=0.70, Compliance=0.90, Ethics=0.80, Feasibility=0.00, Simplicity=1.00\n"
     ]
    }
   ],
   "source": [
    "# We'll iterate through our gene pool and print a formatted summary of each entry's performance.\n",
    "print(\"SOP Gene Pool Evaluation Summary:\")\n",
    "print(\"---------------------------------\")\n",
    "for entry in gene_pool.pool:\n",
    "    v = entry['version']\n",
    "    p = entry['parent']\n",
    "    evals = entry['evaluation']\n",
    "    # Extract the score from each GradedScore object.\n",
    "    r, c, e, f, s = evals.rigor.score, evals.compliance.score, evals.ethics.score, evals.feasibility.score, evals.simplicity.score\n",
    "    parent_str = f\"(Parent)\" if p is None else f\"(Child of v{p})\"\n",
    "    print(f\"SOP v{v:<2} {parent_str:<14}: Rigor={r:.2f}, Compliance={c:.2f}, Ethics={e:.2f}, Feasibility={f:.2f}, Simplicity={s:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4648f60",
   "metadata": {},
   "source": [
    "### Identifying the Pareto Front\n",
    "\n",
    "Now, we need to formalize the concept of an “optimal trade-off”. In our gene pool, some solutions might be strictly worse than others. For example, SOP v3 has the same scores as SOP v1 on four metrics and is equal on feasibility. There’s no reason to ever choose v3. We say that v3 is “dominated” by v1.\n",
    "\n",
    "The Pareto Front is the set of all non-dominated solutions. We’ll write a function to identify this set from our gene pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e68f243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def identify_pareto_front(gene_pool: SOPGenePool) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Identifies the non-dominated solutions (the Pareto Front) in the gene pool.\"\"\"\n",
    "    pareto_front = []\n",
    "    pool_entries = gene_pool.pool\n",
    "    \n",
    "    # We compare every solution against every other solution.\n",
    "    for i, candidate in enumerate(pool_entries):\n",
    "        is_dominated = False\n",
    "        # Get the 5D score vector for the candidate.\n",
    "        cand_scores = np.array([s['score'] for s in candidate['evaluation'].model_dump().values()])\n",
    "        \n",
    "        for j, other in enumerate(pool_entries):\n",
    "            if i == j: continue # Don't compare a solution to itself.\n",
    "            # Get the 5D score vector for the other solution.\n",
    "            other_scores = np.array([s['score'] for s in other['evaluation'].model_dump().values()])\n",
    "            \n",
    "            # The domination condition: 'other' dominates 'candidate' if it is better or equal on ALL scores,\n",
    "            # AND it is strictly better on AT LEAST ONE score.\n",
    "            if np.all(other_scores >= cand_scores) and np.any(other_scores > cand_scores):\n",
    "                is_dominated = True\n",
    "                break # We can stop checking as soon as we find one solution that dominates it.\n",
    "        \n",
    "        # If, after checking all other solutions, none dominated our candidate, it's on the Pareto Front.\n",
    "        if not is_dominated:\n",
    "            pareto_front.append(candidate)\n",
    "            \n",
    "    return pareto_front"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1115555",
   "metadata": {},
   "source": [
    "The identify_pareto_front function is a classic implementation of a Pareto dominance check. It's a brute-force but effective algorithm that systematically compares each SOP's 5D performance vector against every other SOP's vector. The logic np.all(other_scores >= cand_scores) and np.any(other_scores > cand_scores) is the formal mathematical definition of Pareto dominance. This function will distill our entire gene pool down to only the most rational, optimal choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8a3a331a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOPs on the Pareto Front:\n",
      "-------------------------\n",
      "SOP v1: Rigor=0.80, Compliance=0.90, Ethics=0.90, Feasibility=0.00, Simplicity=1.00\n"
     ]
    }
   ],
   "source": [
    "# Run the function to identify the optimal SOPs.\n",
    "pareto_sops = identify_pareto_front(gene_pool)\n",
    "\n",
    "print(\"SOPs on the Pareto Front:\")\n",
    "print(\"-------------------------\")\n",
    "for entry in pareto_sops:\n",
    "    v = entry['version']\n",
    "    evals = entry['evaluation']\n",
    "    r, c, e, f, s = evals.rigor.score, evals.compliance.score, evals.ethics.score, evals.feasibility.score, evals.simplicity.score\n",
    "    print(f\"SOP v{v}: Rigor={r:.2f}, Compliance={c:.2f}, Ethics={e:.2f}, Feasibility={f:.2f}, Simplicity={s:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bde4092",
   "metadata": {},
   "source": [
    "This is the final, distilled output of our entire system. It doesn’t give us a single “best” answer. Instead, it presents a human decision-maker with a menu of optimal, but different, strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf3a738",
   "metadata": {},
   "source": [
    "### Visualizing the Frontier & Making a Decision\n",
    "\n",
    "Visualizing a 5-dimensional space is impossible. However, there are techniques for showing high-dimensional trade-offs. One of the best is the parallel coordinates plot. This plot draws each of our SOPs as a line, with each vertical axis representing one of our five performance pillars. It allows us to instantly see how each strategy performs across all dimensions and where the trade-offs lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "85c484ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def visualize_frontier(pareto_sops):\n",
    "    \"\"\"Creates a 2D scatter plot and a parallel coordinates plot to visualize the Pareto front.\"\"\"\n",
    "    if not pareto_sops:\n",
    "        print(\"No SOPs on the Pareto front to visualize.\")\n",
    "        return\n",
    "    # Create a figure with two subplots side-by-side.\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    # --- Plot 1: 2D Scatter Plot (Rigor vs. Feasibility) ---\n",
    "    labels = [f\"v{s['version']}\" for s in pareto_sops]\n",
    "    rigor_scores = [s['evaluation'].rigor.score for s in pareto_sops]\n",
    "    feasibility_scores = [s['evaluation'].feasibility.score for s in pareto_sops]\n",
    "    \n",
    "    ax1.scatter(rigor_scores, feasibility_scores, s=200, alpha=0.7, c='blue')\n",
    "    for i, txt in enumerate(labels):\n",
    "        ax1.annotate(txt, (rigor_scores[i], feasibility_scores[i]), xytext=(10,-10), textcoords='offset points', fontsize=14)\n",
    "    ax1.set_title('Pareto Frontier: Rigor vs. Feasibility', fontsize=16)\n",
    "    ax1.set_xlabel('Scientific Rigor Score', fontsize=14)\n",
    "    ax1.set_ylabel('Recruitment Feasibility Score', fontsize=14)\n",
    "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax1.set_xlim(min(rigor_scores)-0.05, max(rigor_scores)+0.05)\n",
    "    ax1.set_ylim(min(feasibility_scores)-0.1, max(feasibility_scores)+0.1)\n",
    "\n",
    "    # --- Plot 2: Parallel Coordinates Plot for 5D Analysis ---\n",
    "    data = []\n",
    "    for s in pareto_sops:\n",
    "        eval_dict = s['evaluation'].model_dump()\n",
    "        scores = {k.capitalize(): v['score'] for k, v in eval_dict.items()}\n",
    "        scores['SOP Version'] = f\"v{s['version']}\"\n",
    "        data.append(scores)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # The core plotting function from pandas.\n",
    "    pd.plotting.parallel_coordinates(df, 'SOP Version', colormap=plt.get_cmap(\"viridis\"), ax=ax2, axvlines_kwargs={\"linewidth\": 1, \"color\": \"grey\"})\n",
    "    ax2.set_title('5D Performance Trade-offs on Pareto Front', fontsize=16)\n",
    "    ax2.grid(True, which='major', axis='y', linestyle='--', alpha=0.6)\n",
    "    ax2.set_ylabel('Normalized Score', fontsize=14)\n",
    "    ax2.legend(loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=len(labels))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ee12b",
   "metadata": {},
   "source": [
    "This visualize_frontier function is our final reporting tool. It takes the list of optimal pareto_sops and creates two powerful visualizations. \n",
    "\n",
    "The scatter plot provides a classic view of the two-dimensional trade-off between our most conflicting objectives.\n",
    "\n",
    "The parallel coordinates plot is the main key, it displays the full 5D performance profile of each optimal SOP, allowing a human decision-maker to see the complete picture at a glance.\n",
    "\n",
    "Let’s run the visualization on our identified Pareto front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of this cell will be the Matplotlib plot showing our two visualizations.\n",
    "visualize_frontier(pareto_sops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12077f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_ecosystem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
